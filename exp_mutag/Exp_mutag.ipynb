{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/cluster/home/kamara/.local/lib/python3.7/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c106detail12infer_schema20make_function_schemaENS_8ArrayRefINS1_11ArgumentDefEEES4_",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-35c7ed9ff674>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgen_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_gz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_mutag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Explain/gen_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mk_hop_subgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfrom_scipy_sparse_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_scipy_sparse_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch_geometric/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_debug_enabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_debug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch_geometric/data/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mhetero_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeteroData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtemporal\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTemporalData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch_geometric/data/data.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m from typing import (Optional, Dict, Any, Union, List, Iterable, Tuple,\n\u001b[1;32m      2\u001b[0m                     NamedTuple, Callable)\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNodeType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEdgeType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch_geometric/typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Types for accessing data ####################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch_sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda_spec\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcpu_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_library\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         raise ImportError(f\"Could not find module '{library}_cpu' in \"\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/_ops.py\u001b[0m in \u001b[0;36mload_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;31m# static (global) initialization code in order to register custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# operators with the JIT.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded_libraries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: /cluster/home/kamara/.local/lib/python3.7/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN3c106detail12infer_schema20make_function_schemaENS_8ArrayRefINS1_11ArgumentDefEEES4_"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys,os\n",
    "sys.path.append('/cluster/home/kamara/Explain/')\n",
    "\n",
    "import torch\n",
    "#from torch_geometric.data import download_url\n",
    "\n",
    "\n",
    "from gen_utils import check_dir\n",
    "from dataset import extract_zip, extract_gz, process_mutag, collate_data\n",
    "\n",
    "sys.path.append('/cluster/home/kamara/Explain/exp_synthetic')\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import pandas.util.testing as tm\n",
    "\n",
    "import torch\n",
    "import scipy.sparse\n",
    "from torch import Tensor\n",
    "from torch.utils.dlpack import to_dlpack, from_dlpack\n",
    "\n",
    "import torch_geometric.data\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx, to_networkx\n",
    "from torch_geometric.utils import k_hop_subgraph, from_scipy_sparse_matrix, to_scipy_sparse_matrix\n",
    "from torch_geometric.utils import is_undirected, to_undirected\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from pgmpy.estimators.CITests import chi_square\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BatchNorm1d\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('/cluster/home/kamara/Explain')\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "\n",
    "from gen_utils import check_dir, get_subgraph, from_edge_index_to_adj, from_adj_to_edge_index\n",
    "from parser_utils import arg_parse\n",
    "from graph_utils import *\n",
    "from math_utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-20d659617edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_save_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheck_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_save_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mraw_data_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_save_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raw_data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Save data_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_dir' is not defined"
     ]
    }
   ],
   "source": [
    "data_name = 'mutag'\n",
    "data_save_dir = os.path.join('data', data_name)\n",
    "\n",
    "check_dir(data_save_dir)\n",
    "raw_data_dir = os.path.join(data_save_dir, 'raw_data')\n",
    "# Save data_list\n",
    "data_filename = os.path.join(data_save_dir, data_name) + '.pt'\n",
    "\n",
    "#download MUTAG from url and put it in raw_dir\n",
    "url = 'https://github.com/divelab/DIG_storage/raw/main/xgraph/datasets/MUTAG.zip'\n",
    "\n",
    "path = download_url(url, raw_data_dir)\n",
    "if url[-2:] == 'gz':\n",
    "    extract_gz(path, raw_data_dir)\n",
    "    os.unlink(path)\n",
    "elif url[-3:] == 'zip':\n",
    "    extract_zip(path, raw_data_dir)\n",
    "    os.unlink(path)\n",
    "\n",
    "data_list = process_mutag(raw_data_dir)\n",
    "torch.save(collate_data(data_list), data_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import to_networkx\n",
    "import networkx as nx\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_graphs = len(data_list)\n",
    "print(n_graphs)\n",
    "\n",
    "for i in range(10):\n",
    "    d = data_list[i]\n",
    "    atoms = np.argmax(d.x, axis=1)\n",
    "    g = to_networkx(d)\n",
    "    \n",
    "    plt.figure()\n",
    "    nx.draw(g, cmap=plt.get_cmap('tab10'), node_color=atoms, with_labels=True, font_weight='bold', vmin =0, vmax=6)\n",
    "    plt.show()\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# GCN basic operation\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            output_dim,\n",
    "            add_self=False,\n",
    "            normalize_embedding=False,\n",
    "            dropout=0.0,\n",
    "            bias=True,\n",
    "            gpu=True,\n",
    "            att=False,\n",
    "    ):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.gpu = gpu\n",
    "        self.att = att\n",
    "        self.add_self = add_self\n",
    "        self.dropout = dropout\n",
    "        if dropout > 0.001:\n",
    "            self.dropout_layer = nn.Dropout(p=dropout)\n",
    "        self.normalize_embedding = normalize_embedding\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        if not gpu:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim)\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(torch.FloatTensor(input_dim, input_dim))\n",
    "        else:\n",
    "            self.weight = nn.Parameter(torch.FloatTensor(input_dim, output_dim).cuda())\n",
    "            if add_self:\n",
    "                self.self_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, output_dim).cuda()\n",
    "                )\n",
    "            if att:\n",
    "                self.att_weight = nn.Parameter(\n",
    "                    torch.FloatTensor(input_dim, input_dim).cuda()\n",
    "                )\n",
    "        if bias:\n",
    "            if not gpu:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim))\n",
    "            else:\n",
    "                self.bias = nn.Parameter(torch.FloatTensor(output_dim).cuda())\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "        # self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        if self.dropout > 0.001:\n",
    "            x = self.dropout_layer(x)\n",
    "        # deg = torch.sum(adj, -1, keepdim=True)\n",
    "        if self.att:\n",
    "            x_att = torch.matmul(x, self.att_weight)\n",
    "            # import pdb\n",
    "            # pdb.set_trace()\n",
    "            att = x_att @ x_att.permute(0, 2, 1)\n",
    "            # att = self.softmax(att)\n",
    "            adj = adj * att\n",
    "            \n",
    "        if self.gpu:\n",
    "            adj = adj.cuda()\n",
    "            x = x.cuda()\n",
    "            self.weight = nn.Parameter(self.weight.cuda())\n",
    "            \n",
    "        y = torch.matmul(adj, x)\n",
    "        y = torch.matmul(y, self.weight)\n",
    "        if self.add_self:\n",
    "            self_emb = torch.matmul(x, self.self_weight)\n",
    "            y += self_emb\n",
    "        if self.bias is not None:\n",
    "            y = y + self.bias\n",
    "        # if self.normalize_embedding:\n",
    "        # y = F.normalize(y, p=2, dim=2)\n",
    "        # print(y[0][0])\n",
    "        return y, adj\n",
    "\n",
    "\n",
    "class GcnEncoderGraph(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            label_dim,\n",
    "            num_layers,\n",
    "            pred_hidden_dims=[],\n",
    "            concat=True,\n",
    "            bn=True,\n",
    "            dropout=0.0,\n",
    "            add_self=False,\n",
    "            args=None,\n",
    "    ):\n",
    "        super(GcnEncoderGraph, self).__init__()\n",
    "        self.concat = concat\n",
    "        add_self = add_self\n",
    "        self.bn = bn\n",
    "        self.num_layers = num_layers\n",
    "        self.num_aggs = 1\n",
    "\n",
    "        self.bias = True\n",
    "        self.gpu = args.gpu\n",
    "        if args.method == \"att\":\n",
    "            self.att = True\n",
    "        else:\n",
    "            self.att = False\n",
    "        # if args is not None:\n",
    "        # self.bias = args.bias\n",
    "\n",
    "        self.conv_first, self.conv_block, self.conv_last = self.build_conv_layers(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            num_layers,\n",
    "            add_self,\n",
    "            normalize=True,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.act = nn.ReLU()\n",
    "        self.label_dim = label_dim\n",
    "\n",
    "        if concat:\n",
    "            self.pred_input_dim = hidden_dim * (num_layers - 1) + embedding_dim\n",
    "        else:\n",
    "            self.pred_input_dim = embedding_dim\n",
    "        self.pred_model = self.build_pred_layers(\n",
    "            self.pred_input_dim, pred_hidden_dims, label_dim, num_aggs=self.num_aggs\n",
    "        )\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, GraphConv):\n",
    "                init.xavier_uniform_(m.weight.data, gain=nn.init.calculate_gain(\"relu\"))\n",
    "                if m.att:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.att_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.add_self:\n",
    "                    init.xavier_uniform_(\n",
    "                        m.self_weight.data, gain=nn.init.calculate_gain(\"relu\")\n",
    "                    )\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "    def build_conv_layers(\n",
    "            self,\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            num_layers,\n",
    "            add_self,\n",
    "            normalize=False,\n",
    "            dropout=0.0,\n",
    "    ):\n",
    "        conv_first = GraphConv(\n",
    "            input_dim=input_dim,\n",
    "            output_dim=hidden_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        conv_block = nn.ModuleList(\n",
    "            [\n",
    "                GraphConv(\n",
    "                    input_dim=hidden_dim,\n",
    "                    output_dim=hidden_dim,\n",
    "                    add_self=add_self,\n",
    "                    normalize_embedding=normalize,\n",
    "                    dropout=dropout,\n",
    "                    bias=self.bias,\n",
    "                    gpu=self.gpu,\n",
    "                    att=self.att,\n",
    "                )\n",
    "                for i in range(num_layers - 2)\n",
    "            ]\n",
    "        )\n",
    "        conv_last = GraphConv(\n",
    "            input_dim=hidden_dim,\n",
    "            output_dim=embedding_dim,\n",
    "            add_self=add_self,\n",
    "            normalize_embedding=normalize,\n",
    "            bias=self.bias,\n",
    "            gpu=self.gpu,\n",
    "            att=self.att,\n",
    "        )\n",
    "        return conv_first, conv_block, conv_last\n",
    "\n",
    "    def build_pred_layers(\n",
    "            self, pred_input_dim, pred_hidden_dims, label_dim, num_aggs=1\n",
    "    ):\n",
    "        pred_input_dim = pred_input_dim * num_aggs\n",
    "        if len(pred_hidden_dims) == 0:\n",
    "            pred_model = nn.Linear(pred_input_dim, label_dim)\n",
    "        else:\n",
    "            pred_layers = []\n",
    "            for pred_dim in pred_hidden_dims:\n",
    "                pred_layers.append(nn.Linear(pred_input_dim, pred_dim))\n",
    "                pred_layers.append(self.act)\n",
    "                pred_input_dim = pred_dim\n",
    "            pred_layers.append(nn.Linear(pred_dim, label_dim))\n",
    "            pred_model = nn.Sequential(*pred_layers)\n",
    "        return pred_model\n",
    "\n",
    "    def construct_mask(self, max_nodes, batch_num_nodes):\n",
    "        \"\"\" For each num_nodes in batch_num_nodes, the first num_nodes entries of the\n",
    "        corresponding column are 1's, and the rest are 0's (to be masked out).\n",
    "        Dimension of mask: [batch_size x max_nodes x 1]\n",
    "        \"\"\"\n",
    "        # masks\n",
    "        packed_masks = [torch.ones(int(num)) for num in batch_num_nodes]\n",
    "        batch_size = len(batch_num_nodes)\n",
    "        out_tensor = torch.zeros(batch_size, max_nodes)\n",
    "        for i, mask in enumerate(packed_masks):\n",
    "            out_tensor[i, : batch_num_nodes[i]] = mask\n",
    "        if self.gpu:\n",
    "            out = out_tensor.unsqueeze(2).cuda()\n",
    "        else:\n",
    "            out = out_tensor.unsqueeze(2)\n",
    "        return out\n",
    "\n",
    "    def apply_bn(self, x):\n",
    "        \"\"\" Batch normalization of 3D tensor x\n",
    "        \"\"\"\n",
    "        bn_module = nn.BatchNorm1d(x.size()[1])\n",
    "        if self.gpu:\n",
    "            bn_module = bn_module.cuda()\n",
    "        return bn_module(x)\n",
    "\n",
    "    def gcn_forward(\n",
    "            self, x, adj, conv_first, conv_block, conv_last, embedding_mask=None\n",
    "    ):\n",
    "\n",
    "        \"\"\" Perform forward prop with graph convolution.\n",
    "        Returns:\n",
    "            Embedding matrix with dimension [batch_size x num_nodes x embedding]\n",
    "            The embedding dim is self.pred_input_dim\n",
    "        \"\"\"\n",
    "        x, adj_att = conv_first(x, adj)\n",
    "        x = self.act(x)\n",
    "        if self.bn:\n",
    "            x = self.apply_bn(x)\n",
    "        x_all = [x]\n",
    "        adj_att_all = [adj_att]\n",
    "        # out_all = []\n",
    "        # out, _ = torch.max(x, dim=1)\n",
    "        # out_all.append(out)\n",
    "        for i in range(len(conv_block)):\n",
    "            x, _ = conv_block[i](x, adj)\n",
    "            x = self.act(x)\n",
    "            if self.bn:\n",
    "                x = self.apply_bn(x)\n",
    "            x_all.append(x)\n",
    "            adj_att_all.append(adj_att)\n",
    "        x, adj_att = conv_last(x, adj)\n",
    "        x_all.append(x)\n",
    "        adj_att_all.append(adj_att)\n",
    "        # x_tensor: [batch_size x num_nodes x embedding]\n",
    "        x_tensor = torch.cat(x_all, dim=2)\n",
    "        if embedding_mask is not None:\n",
    "            x_tensor = x_tensor * embedding_mask\n",
    "        self.embedding_tensor = x_tensor\n",
    "\n",
    "        # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "        adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "        return x_tensor, adj_att_tensor\n",
    "\n",
    "    def forward_batch(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "        # mask\n",
    "        max_num_nodes = adj.size()[1]\n",
    "        if batch_num_nodes is not None:\n",
    "            self.embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "        else:\n",
    "            self.embedding_mask = None\n",
    "\n",
    "        # conv\n",
    "        x, adj_att = self.conv_first(x, adj)\n",
    "        x = self.act(x)\n",
    "        if self.bn:\n",
    "            x = self.apply_bn(x)\n",
    "        out_all = []\n",
    "        out, _ = torch.max(x, dim=1)\n",
    "        out_all.append(out)\n",
    "        adj_att_all = [adj_att]\n",
    "        for i in range(self.num_layers - 2):\n",
    "            x, adj_att = self.conv_block[i](x, adj)\n",
    "            x = self.act(x)\n",
    "            if self.bn:\n",
    "                x = self.apply_bn(x)\n",
    "            out, _ = torch.max(x, dim=1)\n",
    "            out_all.append(out)\n",
    "            if self.num_aggs == 2:\n",
    "                out = torch.sum(x, dim=1)\n",
    "                out_all.append(out)\n",
    "            adj_att_all.append(adj_att)\n",
    "        x, adj_att = self.conv_last(x, adj)\n",
    "        adj_att_all.append(adj_att)\n",
    "        # x = self.act(x)\n",
    "        out, _ = torch.max(x, dim=1)\n",
    "        out_all.append(out)\n",
    "        if self.num_aggs == 2:\n",
    "            out = torch.sum(x, dim=1)\n",
    "            out_all.append(out)\n",
    "        if self.concat:\n",
    "            output = torch.cat(out_all, dim=1)\n",
    "        else:\n",
    "            output = out\n",
    "\n",
    "        # adj_att_tensor: [batch_size x num_nodes x num_nodes x num_gc_layers]\n",
    "        adj_att_tensor = torch.stack(adj_att_all, dim=3)\n",
    "\n",
    "        self.embedding_tensor = output\n",
    "        ypred = self.pred_model(output)\n",
    "        # print(output.size())\n",
    "        return ypred, adj_att_tensor\n",
    "    \n",
    "    def forward(self, x, edge_index, batch_num_nodes=None, **kwargs):\n",
    "        # Encoder Node receives no batch - only one graph\n",
    "        if x.ndim<3:\n",
    "            x = x.expand(1,-1,-1)\n",
    "            edge_index = edge_index.expand(1,-1,-1)\n",
    "        adj=[]\n",
    "        for i in range(len(x)):\n",
    "            max_n = torch.Tensor(x[i]).size(0)\n",
    "            adj.append(from_edge_index_to_adj(edge_index[i], max_n))\n",
    "        adj = torch.stack(adj)\n",
    "        \n",
    "        if self.gpu:\n",
    "            adj = adj.cuda()\n",
    "        pred, adj_att = self.forward_batch(x, adj, batch_num_nodes, **kwargs)\n",
    "        return pred\n",
    "\n",
    "    def loss(self, pred, label, type=\"softmax\"):\n",
    "        # softmax + CE\n",
    "        if type == \"softmax\":\n",
    "            return F.cross_entropy(pred, label, size_average=True)\n",
    "        elif type == \"margin\":\n",
    "            batch_size = pred.size()[0]\n",
    "            label_onehot = torch.zeros(batch_size, self.label_dim).long().cuda()\n",
    "            label_onehot.scatter_(1, label.view(-1, 1), 1)\n",
    "            return torch.nn.MultiLabelMarginLoss()(pred, label_onehot)\n",
    "\n",
    "        # return F.binary_cross_entropy(F.sigmoid(pred[:,0]), label.float())\n",
    "\n",
    "\n",
    "class GcnEncoderNode(GcnEncoderGraph):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            label_dim,\n",
    "            num_layers,\n",
    "            pred_hidden_dims=[],\n",
    "            concat=True,\n",
    "            bn=True,\n",
    "            dropout=0.0,\n",
    "            args=None,\n",
    "    ):\n",
    "        super(GcnEncoderNode, self).__init__(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            embedding_dim,\n",
    "            label_dim,\n",
    "            num_layers,\n",
    "            pred_hidden_dims,\n",
    "            concat,\n",
    "            bn,\n",
    "            dropout,\n",
    "            args=args,\n",
    "        )\n",
    "        # if hasattr(args, \"loss_weight\"):\n",
    "        # print(\"Loss weight: \", args.loss_weight)\n",
    "        # self.celoss = nn.CrossEntropyLoss(weight=args.loss_weight)\n",
    "        # else:\n",
    "        self.celoss = nn.CrossEntropyLoss()\n",
    "        self.gpu = args.gpu\n",
    "\n",
    "    def forward_batch(self, x, adj, batch_num_nodes=None, **kwargs):\n",
    "        # mask\n",
    "        max_num_nodes = adj.size()[1]\n",
    "        if batch_num_nodes is not None:\n",
    "            embedding_mask = self.construct_mask(max_num_nodes, batch_num_nodes)\n",
    "        else:\n",
    "            embedding_mask = None\n",
    "        self.adj_atts = []\n",
    "        self.embedding_tensor, adj_att = self.gcn_forward(\n",
    "            x, adj, self.conv_first, self.conv_block, self.conv_last, embedding_mask\n",
    "        )\n",
    "        if self.gpu:\n",
    "            self.embedding_tensor = self.embedding_tensor.cuda()\n",
    "            self.pred_model = self.pred_model.cuda()\n",
    "        pred = self.pred_model(self.embedding_tensor)\n",
    "        return pred, adj_att\n",
    "\n",
    "    def forward(self, x, edge_index, batch_num_nodes=None, **kwargs):\n",
    "        # Encoder Node receives no batch - only one graph\n",
    "        max_n = x.size(0)\n",
    "        adj = from_edge_index_to_adj(edge_index, max_n)\n",
    "        if self.gpu:\n",
    "            adj = adj.cuda()\n",
    "        pred, adj_att = self.forward_batch(x.expand(1, -1, -1), adj.expand(1, -1, -1), batch_num_nodes, **kwargs)\n",
    "        ypred = torch.squeeze(pred, 0)\n",
    "        return ypred\n",
    "\n",
    "    def loss(self, pred, label):\n",
    "        # Transpose if batch dim:\n",
    "        # pred = torch.transpose(pred, 1, 2)\n",
    "        return self.celoss(pred, label)\n",
    "\n",
    "####### Evaluate GNN #######\n",
    "\n",
    "def get_proba(ypred):\n",
    "    m = nn.Softmax(dim=1)\n",
    "    yprob = m(ypred)\n",
    "    return yprob\n",
    "\n",
    "def get_labels(ypred):\n",
    "    ylabels = torch.argmax(ypred, dim=1)\n",
    "    return ylabels\n",
    "\n",
    "\n",
    "def gnn_scores(model, data):\n",
    "    ypred = model(data.x, data.edge_index)\n",
    "    ylabels = get_labels(ypred).cpu()\n",
    "    data.y = data.y.cpu()\n",
    "    \n",
    "    result_train = {\n",
    "        \"prec\": metrics.precision_score(data.y[data.train_mask], ylabels[data.train_mask], average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(data.y[data.train_mask], ylabels[data.train_mask], average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(data.y[data.train_mask], ylabels[data.train_mask])\n",
    "        #\"conf_mat\": metrics.confusion_matrix(data.y[data.train_mask], ylabels[data.train_mask]),\n",
    "    }\n",
    "\n",
    "    result_test = {\n",
    "        \"prec\": metrics.precision_score(data.y[data.test_mask], ylabels[data.test_mask], average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(data.y[data.test_mask], ylabels[data.test_mask], average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(data.y[data.test_mask], ylabels[data.test_mask])#,\n",
    "        #\"conf_mat\": metrics.confusion_matrix(data.y[data.test_mask], ylabels[data.test_mask]),\n",
    "    }\n",
    "    return result_train, result_test\n",
    "\n",
    "####### GNN Training #######\n",
    "def train(model, data, device, args):\n",
    "\n",
    "    data = data.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "    # scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    # scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "    # scheduler = StepLR(optimizer, step_size=100, gamma=0.96)\n",
    "\n",
    "    val_err = []\n",
    "    train_err = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(args.num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(data.x, data.edge_index)\n",
    "\n",
    "        loss = model.loss(out[data.train_mask], data.y[data.train_mask])\n",
    "        val_loss = model.loss(out[data.val_mask], data.y[data.val_mask])\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "            val_err.append(val_loss.item())\n",
    "            train_err.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        # scheduler.step(val_loss)\n",
    "\n",
    "    #plt.figure()\n",
    "    #plt.plot(range(args.num_epochs // 10), val_err)\n",
    "    #plt.plot(range(args.num_epochs // 10), train_err)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_model(model, args):\n",
    "    filename = os.path.join(args.save_dir, args.dataset) + \"gcn.pth.tar\"\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model_type\": 'gcn',\n",
    "            \"model_state\": model.state_dict()\n",
    "        },\n",
    "        str(filename),\n",
    "    )\n",
    "\n",
    "def load_model(args):\n",
    "    '''Load a pre-trained pytorch model from checkpoint.\n",
    "        '''\n",
    "    print(\"loading model\")\n",
    "    filename = os.path.join(args.save_dir, args.dataset) + \"/gcn.pth.tar\"\n",
    "    print(filename)\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        ckpt = torch.load(filename)\n",
    "    else:\n",
    "        print(\"Checkpoint does not exist!\")\n",
    "        print(\"Checked path -- {}\".format(filename))\n",
    "        print(\"Make sure you have provided the correct path!\")\n",
    "        print(\"You may have forgotten to train a model for this dataset.\")\n",
    "        print()\n",
    "        print(\"To train one of the paper's models, run the following\")\n",
    "        print(\">> python train_gnn.py --dataset=DATASET_NAME\")\n",
    "        print()\n",
    "        raise Exception(\"File not found.\")\n",
    "    return ckpt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c8eb10f66c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttributeDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mdata_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_list' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "args = {\"dataset\": \"mutag\", \"input_dim\":7, \"val_ratio\": 0.15, \"test_ratio\": 0.1, \"train_ratio\": 0.8, 'gpu':False, 'method':'base', 'seed': 10}\n",
    "args['num_top_edges']=6\n",
    "args['threshold']=0.7\n",
    "args['num_test_nodes'] = 10\n",
    "args['num_gc_layers']=3\n",
    "args['num_epochs']=200\n",
    "args[\"feature_type\"] = \"default\"\n",
    "args[\"batch_size\"] = 20\n",
    "args['num_workers'] = 1\n",
    "args['clip']=2.0\n",
    "\n",
    "class AttributeDict(dict):\n",
    "    __slots__ = () \n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "    \n",
    "    \n",
    "args = AttributeDict(args)\n",
    "\n",
    "data_list[0].x.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class GraphSampler(torch.utils.data.Dataset):\n",
    "    \"\"\" Sample graphs and nodes in graph\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        G_list,\n",
    "        features=\"default\",\n",
    "        normalize=True,\n",
    "        assign_feat=\"default\",\n",
    "        max_num_nodes=0,\n",
    "    ):\n",
    "        self.adj_all = []\n",
    "        self.len_all = []\n",
    "        self.feature_all = []\n",
    "        self.label_all = []\n",
    "\n",
    "        self.assign_feat_all = []\n",
    "\n",
    "        if max_num_nodes == 0:\n",
    "            self.max_num_nodes = max([G.number_of_nodes() for G in G_list])\n",
    "        else:\n",
    "            self.max_num_nodes = max_num_nodes\n",
    "\n",
    "        existing_node = list(G_list[0].nodes())[-1]\n",
    "        self.feat_dim = G_list[0].nodes[existing_node][\"feat\"].shape[0]\n",
    "\n",
    "        for G in G_list:\n",
    "            adj = np.array(nx.to_numpy_matrix(G))\n",
    "            if normalize:\n",
    "                sqrt_deg = np.diag(\n",
    "                    1.0 / np.sqrt(np.sum(adj, axis=0, dtype=float).squeeze())\n",
    "                )\n",
    "                adj = np.matmul(np.matmul(sqrt_deg, adj), sqrt_deg)\n",
    "            self.adj_all.append(adj)\n",
    "            self.len_all.append(G.number_of_nodes())\n",
    "            self.label_all.append(G.graph[\"label\"])\n",
    "            # feat matrix: max_num_nodes x feat_dim\n",
    "            if features == \"default\":\n",
    "                f = np.zeros((self.max_num_nodes, self.feat_dim), dtype=float)\n",
    "                for i, u in enumerate(G.nodes()):\n",
    "                    f[i, :] = G.nodes[u][\"feat\"]\n",
    "                self.feature_all.append(f)\n",
    "            elif features == \"id\":\n",
    "                self.feature_all.append(np.identity(self.max_num_nodes))\n",
    "            elif features == \"deg-num\":\n",
    "                degs = np.sum(np.array(adj), 1)\n",
    "                degs = np.expand_dims(\n",
    "                    np.pad(degs, [0, self.max_num_nodes - G.number_of_nodes()], 0),\n",
    "                    axis=1,\n",
    "                )\n",
    "                self.feature_all.append(degs)\n",
    "            elif features == \"deg\":\n",
    "                self.max_deg = 10\n",
    "                degs = np.sum(np.array(adj), 1).astype(int)\n",
    "                degs[degs > self.max_deg] = self.max_deg\n",
    "                feat = np.zeros((len(degs), self.max_deg + 1))\n",
    "                feat[np.arange(len(degs)), degs] = 1\n",
    "                feat = np.pad(\n",
    "                    feat,\n",
    "                    ((0, self.max_num_nodes - G.number_of_nodes()), (0, 0)),\n",
    "                    \"constant\",\n",
    "                    constant_values=0,\n",
    "                )\n",
    "\n",
    "                f = np.zeros((self.max_num_nodes, self.feat_dim), dtype=float)\n",
    "                for i, u in enumerate(G.nodes()):\n",
    "                    f[i, :] = G.nodes[u][\"feat\"]\n",
    "\n",
    "                feat = np.concatenate((feat, f), axis=1)\n",
    "\n",
    "                self.feature_all.append(feat)\n",
    "            elif features == \"struct\":\n",
    "                self.max_deg = 10\n",
    "                degs = np.sum(np.array(adj), 1).astype(int)\n",
    "                degs[degs > 10] = 10\n",
    "                feat = np.zeros((len(degs), self.max_deg + 1))\n",
    "                feat[np.arange(len(degs)), degs] = 1\n",
    "                degs = np.pad(\n",
    "                    feat,\n",
    "                    ((0, self.max_num_nodes - G.number_of_nodes()), (0, 0)),\n",
    "                    \"constant\",\n",
    "                    constant_values=0,\n",
    "                )\n",
    "\n",
    "                clusterings = np.array(list(nx.clustering(G).values()))\n",
    "                clusterings = np.expand_dims(\n",
    "                    np.pad(\n",
    "                        clusterings,\n",
    "                        [0, self.max_num_nodes - G.number_of_nodes()],\n",
    "                        \"constant\",\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                )\n",
    "                g_feat = np.hstack([degs, clusterings])\n",
    "                if \"feat\" in G.nodes[0]:\n",
    "                    node_feats = np.array(\n",
    "                        [G.nodes[i][\"feat\"] for i in range(G.number_of_nodes())]\n",
    "                    )\n",
    "                    node_feats = np.pad(\n",
    "                        node_feats,\n",
    "                        ((0, self.max_num_nodes - G.number_of_nodes()), (0, 0)),\n",
    "                        \"constant\",\n",
    "                    )\n",
    "                    g_feat = np.hstack([g_feat, node_feats])\n",
    "\n",
    "                self.feature_all.append(g_feat)\n",
    "\n",
    "            if assign_feat == \"id\":\n",
    "                self.assign_feat_all.append(\n",
    "                    np.hstack((np.identity(self.max_num_nodes), self.feature_all[-1]))\n",
    "                )\n",
    "            else:\n",
    "                self.assign_feat_all.append(self.feature_all[-1])\n",
    "\n",
    "        self.feat_dim = self.feature_all[0].shape[1]\n",
    "        self.assign_feat_dim = self.assign_feat_all[0].shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.adj_all)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        adj = self.adj_all[idx]\n",
    "        num_nodes = adj.shape[0]\n",
    "        adj_padded = np.zeros((self.max_num_nodes, self.max_num_nodes))\n",
    "        adj_padded[:num_nodes, :num_nodes] = adj\n",
    "\n",
    "        # use all nodes for aggregation (baseline)\n",
    "        return {\n",
    "            \"adj\": adj_padded,\n",
    "            \"feats\": self.feature_all[idx].copy(),\n",
    "            \"label\": self.label_all[idx],\n",
    "            \"num_nodes\": num_nodes,\n",
    "            \"assign_feats\": self.assign_feat_all[idx].copy(),\n",
    "        }\n",
    "\n",
    "def neighborhoods(adj, n_hops, use_cuda):\n",
    "    \"\"\"Returns the n_hops degree adjacency matrix adj.\"\"\"\n",
    "    adj = torch.tensor(adj, dtype=torch.float)\n",
    "    if use_cuda:\n",
    "        adj = adj.cuda()\n",
    "    hop_adj = power_adj = adj\n",
    "    for i in range(n_hops - 1):\n",
    "        power_adj = power_adj @ adj\n",
    "        prev_hop_adj = hop_adj\n",
    "        hop_adj = hop_adj + power_adj\n",
    "        hop_adj = (hop_adj > 0).float()\n",
    "    return hop_adj.cpu().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(graphs, args, test_graphs=None, max_nodes=0):\n",
    "\n",
    "    random.shuffle(graphs)\n",
    "    if test_graphs is None:\n",
    "        train_idx = int(len(graphs) * args.train_ratio)\n",
    "        test_idx = int(len(graphs) * (1 - args.test_ratio))\n",
    "        train_graphs = graphs[:train_idx]\n",
    "        val_graphs = graphs[train_idx:test_idx]\n",
    "        test_graphs = graphs[test_idx:]\n",
    "    else:\n",
    "        train_idx = int(len(graphs) * args.train_ratio)\n",
    "        train_graphs = graphs[:train_idx]\n",
    "        val_graphs = graph[train_idx:]\n",
    "    print(\n",
    "        \"Num training graphs: \",\n",
    "        len(train_graphs),\n",
    "        \"; Num validation graphs: \",\n",
    "        len(val_graphs),\n",
    "        \"; Num testing graphs: \",\n",
    "        len(test_graphs),\n",
    "    )\n",
    "\n",
    "    print(\"Number of graphs: \", len(graphs))\n",
    "    print(\"Number of edges: \", sum([G.number_of_edges() for G in graphs]))\n",
    "    print(\n",
    "        \"Max, avg, std of graph size: \",\n",
    "        max([G.number_of_nodes() for G in graphs]),\n",
    "        \", \" \"{0:.2f}\".format(np.mean([G.number_of_nodes() for G in graphs])),\n",
    "        \", \" \"{0:.2f}\".format(np.std([G.number_of_nodes() for G in graphs])),\n",
    "    )\n",
    "\n",
    "    # minibatch\n",
    "    dataset_sampler = GraphSampler(\n",
    "        train_graphs,\n",
    "        normalize=False,\n",
    "        max_num_nodes=max_nodes,\n",
    "        features=args.feature_type,\n",
    "    )\n",
    "    train_dataset_loader = torch.utils.data.DataLoader(\n",
    "        dataset_sampler,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "\n",
    "    dataset_sampler = GraphSampler(\n",
    "        val_graphs, \n",
    "        normalize=False, \n",
    "        max_num_nodes=max_nodes, \n",
    "        features=args.feature_type\n",
    "    )\n",
    "    val_dataset_loader = torch.utils.data.DataLoader(\n",
    "        dataset_sampler,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "\n",
    "    dataset_sampler = GraphSampler(\n",
    "        test_graphs,\n",
    "        normalize=False,\n",
    "        max_num_nodes=max_nodes,\n",
    "        features=args.feature_type,\n",
    "    )\n",
    "    test_dataset_loader = torch.utils.data.DataLoader(\n",
    "        dataset_sampler,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=args.num_workers,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        train_dataset_loader,\n",
    "        val_dataset_loader,\n",
    "        test_dataset_loader,\n",
    "        dataset_sampler.max_num_nodes,\n",
    "        dataset_sampler.feat_dim,\n",
    "        dataset_sampler.assign_feat_dim,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "\n",
    "for data in data_list:\n",
    "    data.feat = np.array(data.x)\n",
    "    g = to_networkx(data, node_attrs=['feat'])\n",
    "    g.graph[\"label\"] = np.array(data.y)\n",
    "    graphs.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training graphs:  150 ; Num validation graphs:  19 ; Num testing graphs:  19\n",
      "Number of graphs:  188\n",
      "Number of edges:  7442\n",
      "Max, avg, std of graph size:  28 , 17.93 , 4.58\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset, max_num_nodes, feat_dim, assign_feat_dim = prepare_data(graphs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "def evaluate(dataset, model, args, name=\"Validation\", max_num_examples=None):\n",
    "    model.eval()\n",
    "\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for batch_idx, data in enumerate(dataset):\n",
    "        if args.gpu:\n",
    "            adj = Variable(data[\"adj\"].float(), requires_grad=False).cuda()\n",
    "            h0 = Variable(data[\"feats\"].float()).cuda()\n",
    "            labels.append(data[\"label\"].long().numpy())\n",
    "            batch_num_nodes = data[\"num_nodes\"].int().numpy()\n",
    "            assign_input = Variable(\n",
    "                data[\"assign_feats\"].float(), requires_grad=False\n",
    "            ).cuda()\n",
    "        else:\n",
    "            adj = Variable(data[\"adj\"].float(), requires_grad=False)\n",
    "            h0 = Variable(data[\"feats\"].float())\n",
    "            labels.append(data[\"label\"].long().numpy())\n",
    "            batch_num_nodes = data[\"num_nodes\"].int().numpy()\n",
    "            assign_input = Variable(\n",
    "                data[\"assign_feats\"].float(), requires_grad=False\n",
    "            )\n",
    "            \n",
    "        edge_index = []\n",
    "        for a in adj:\n",
    "            edge_index.append(from_adj_to_edge_index(a))\n",
    "\n",
    "        ypred = model(h0, edge_index, batch_num_nodes, assign_x=assign_input)\n",
    "        _, indices = torch.max(ypred, 1)\n",
    "        preds.append(indices.cpu().data.numpy())\n",
    "\n",
    "        if max_num_examples is not None:\n",
    "            if (batch_idx + 1) * args.batch_size > max_num_examples:\n",
    "                break\n",
    "\n",
    "    labels = np.hstack(labels)\n",
    "    preds = np.hstack(preds)\n",
    "\n",
    "    result = {\n",
    "        \"prec\": metrics.precision_score(labels, preds, average=\"macro\"),\n",
    "        \"recall\": metrics.recall_score(labels, preds, average=\"macro\"),\n",
    "        \"acc\": metrics.accuracy_score(labels, preds),\n",
    "    }\n",
    "    print(name, \" accuracy:\", result[\"acc\"])\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Avg loss:  tensor(1.4933, grad_fn=<DivBackward0>) ; epoch time:  0.17802000045776367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/kamara/.local/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/site-packages/ipykernel_launcher.py:79: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  accuracy: 0.5166666666666667\n",
      "Validation  accuracy: 0.5263157894736842\n",
      "Test  accuracy: 0.42105263157894735\n",
      "Best val result:  {'epoch': 0, 'loss': tensor(1.4933, grad_fn=<DivBackward0>), 'acc': 0.5263157894736842}\n",
      "Test result:  {'prec': 0.3806818181818182, 'recall': 0.35, 'acc': 0.42105263157894735, 'epoch': 0}\n",
      "Epoch:  1\n",
      "Avg loss:  tensor(0.6804, grad_fn=<DivBackward0>) ; epoch time:  0.16155385971069336\n",
      "Train  accuracy: 0.6166666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/nss/gcc-6.3.0/python/3.7.4/x86_64/lib64/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 1, 'loss': tensor(0.6804, grad_fn=<DivBackward0>), 'acc': 0.6842105263157895}\n",
      "Test result:  {'prec': 0.3684210526315789, 'recall': 0.5, 'acc': 0.7368421052631579, 'epoch': 1}\n",
      "Epoch:  2\n",
      "Avg loss:  tensor(0.5890, grad_fn=<DivBackward0>) ; epoch time:  0.16143512725830078\n",
      "Train  accuracy: 0.6416666666666667\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 2, 'loss': tensor(0.5890, grad_fn=<DivBackward0>), 'acc': 0.6842105263157895}\n",
      "Test result:  {'prec': 0.3684210526315789, 'recall': 0.5, 'acc': 0.7368421052631579, 'epoch': 2}\n",
      "Epoch:  3\n",
      "Avg loss:  tensor(0.4467, grad_fn=<DivBackward0>) ; epoch time:  0.15974140167236328\n",
      "Train  accuracy: 0.7916666666666666\n",
      "Validation  accuracy: 0.8947368421052632\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 3, 'loss': tensor(0.4467, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7285714285714285, 'recall': 0.7285714285714285, 'acc': 0.7894736842105263, 'epoch': 3}\n",
      "Epoch:  4\n",
      "Avg loss:  tensor(0.4233, grad_fn=<DivBackward0>) ; epoch time:  0.1585693359375\n",
      "Train  accuracy: 0.8416666666666667\n",
      "Validation  accuracy: 0.8947368421052632\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 4, 'loss': tensor(0.4233, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.6730769230769231, 'recall': 0.6928571428571428, 'acc': 0.7368421052631579, 'epoch': 4}\n",
      "Epoch:  5\n",
      "Avg loss:  tensor(0.3684, grad_fn=<DivBackward0>) ; epoch time:  0.1600809097290039\n",
      "Train  accuracy: 0.8416666666666667\n",
      "Validation  accuracy: 0.8947368421052632\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 5, 'loss': tensor(0.3684, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.6730769230769231, 'recall': 0.6928571428571428, 'acc': 0.7368421052631579, 'epoch': 5}\n",
      "Epoch:  6\n",
      "Avg loss:  tensor(0.3551, grad_fn=<DivBackward0>) ; epoch time:  0.15953922271728516\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.8947368421052632\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 6, 'loss': tensor(0.3551, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.6730769230769231, 'recall': 0.6928571428571428, 'acc': 0.7368421052631579, 'epoch': 6}\n",
      "Epoch:  7\n",
      "Avg loss:  tensor(0.3783, grad_fn=<DivBackward0>) ; epoch time:  0.16238856315612793\n",
      "Train  accuracy: 0.85\n",
      "Validation  accuracy: 0.8947368421052632\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 7, 'loss': tensor(0.3783, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.6730769230769231, 'recall': 0.6928571428571428, 'acc': 0.7368421052631579, 'epoch': 7}\n",
      "Epoch:  8\n",
      "Avg loss:  tensor(0.3435, grad_fn=<DivBackward0>) ; epoch time:  0.16240715980529785\n",
      "Train  accuracy: 0.8416666666666667\n",
      "Validation  accuracy: 0.8947368421052632\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.6730769230769231, 'recall': 0.6928571428571428, 'acc': 0.7368421052631579, 'epoch': 8}\n",
      "Epoch:  9\n",
      "Avg loss:  tensor(0.3492, grad_fn=<DivBackward0>) ; epoch time:  0.16077923774719238\n",
      "Train  accuracy: 0.825\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7285714285714285, 'recall': 0.7285714285714285, 'acc': 0.7894736842105263, 'epoch': 9}\n",
      "Epoch:  10\n",
      "Avg loss:  tensor(0.3012, grad_fn=<DivBackward0>) ; epoch time:  0.16227388381958008\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 10}\n",
      "Epoch:  11\n",
      "Avg loss:  tensor(0.3174, grad_fn=<DivBackward0>) ; epoch time:  0.1621091365814209\n",
      "Train  accuracy: 0.85\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 11}\n",
      "Epoch:  12\n",
      "Avg loss:  tensor(0.3334, grad_fn=<DivBackward0>) ; epoch time:  0.1605818271636963\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 12}\n",
      "Epoch:  13\n",
      "Avg loss:  tensor(0.3091, grad_fn=<DivBackward0>) ; epoch time:  0.17384767532348633\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.8421052631578947\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7948717948717949, 'recall': 0.8285714285714285, 'acc': 0.8421052631578947, 'epoch': 13}\n",
      "Epoch:  14\n",
      "Avg loss:  tensor(0.3665, grad_fn=<DivBackward0>) ; epoch time:  0.168715238571167\n",
      "Train  accuracy: 0.825\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.8421052631578947\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7948717948717949, 'recall': 0.8285714285714285, 'acc': 0.8421052631578947, 'epoch': 14}\n",
      "Epoch:  15\n",
      "Avg loss:  tensor(0.3136, grad_fn=<DivBackward0>) ; epoch time:  0.21408963203430176\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 15}\n",
      "Epoch:  16\n",
      "Avg loss:  tensor(0.3069, grad_fn=<DivBackward0>) ; epoch time:  0.16988158226013184\n",
      "Train  accuracy: 0.85\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 16}\n",
      "Epoch:  17\n",
      "Avg loss:  tensor(0.3862, grad_fn=<DivBackward0>) ; epoch time:  0.1686859130859375\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7285714285714285, 'recall': 0.7285714285714285, 'acc': 0.7894736842105263, 'epoch': 17}\n",
      "Epoch:  18\n",
      "Avg loss:  tensor(0.3089, grad_fn=<DivBackward0>) ; epoch time:  0.16759061813354492\n",
      "Train  accuracy: 0.8166666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 18}\n",
      "Epoch:  19\n",
      "Avg loss:  tensor(0.2891, grad_fn=<DivBackward0>) ; epoch time:  0.1667320728302002\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 19}\n",
      "Epoch:  20\n",
      "Avg loss:  tensor(0.2987, grad_fn=<DivBackward0>) ; epoch time:  0.1705160140991211\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 20}\n",
      "Epoch:  21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.3077, grad_fn=<DivBackward0>) ; epoch time:  0.16440582275390625\n",
      "Train  accuracy: 0.8583333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 21}\n",
      "Epoch:  22\n",
      "Avg loss:  tensor(0.2669, grad_fn=<DivBackward0>) ; epoch time:  0.1668086051940918\n",
      "Train  accuracy: 0.8583333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 22}\n",
      "Epoch:  23\n",
      "Avg loss:  tensor(0.2822, grad_fn=<DivBackward0>) ; epoch time:  0.17064452171325684\n",
      "Train  accuracy: 0.8333333333333334\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 23}\n",
      "Epoch:  24\n",
      "Avg loss:  tensor(0.3161, grad_fn=<DivBackward0>) ; epoch time:  0.17224955558776855\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 24}\n",
      "Epoch:  25\n",
      "Avg loss:  tensor(0.2775, grad_fn=<DivBackward0>) ; epoch time:  0.16570043563842773\n",
      "Train  accuracy: 0.85\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 25}\n",
      "Epoch:  26\n",
      "Avg loss:  tensor(0.2807, grad_fn=<DivBackward0>) ; epoch time:  0.22330737113952637\n",
      "Train  accuracy: 0.825\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 26}\n",
      "Epoch:  27\n",
      "Avg loss:  tensor(0.2910, grad_fn=<DivBackward0>) ; epoch time:  0.1709134578704834\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 27}\n",
      "Epoch:  28\n",
      "Avg loss:  tensor(0.3307, grad_fn=<DivBackward0>) ; epoch time:  0.1679372787475586\n",
      "Train  accuracy: 0.8583333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 28}\n",
      "Epoch:  29\n",
      "Avg loss:  tensor(0.3519, grad_fn=<DivBackward0>) ; epoch time:  0.1703023910522461\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.8421052631578947\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7948717948717949, 'recall': 0.8285714285714285, 'acc': 0.8421052631578947, 'epoch': 29}\n",
      "Epoch:  30\n",
      "Avg loss:  tensor(0.2805, grad_fn=<DivBackward0>) ; epoch time:  0.16044926643371582\n",
      "Train  accuracy: 0.8333333333333334\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 30}\n",
      "Epoch:  31\n",
      "Avg loss:  tensor(0.2695, grad_fn=<DivBackward0>) ; epoch time:  0.1699509620666504\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 31}\n",
      "Epoch:  32\n",
      "Avg loss:  tensor(0.3157, grad_fn=<DivBackward0>) ; epoch time:  0.1687455177307129\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 32}\n",
      "Epoch:  33\n",
      "Avg loss:  tensor(0.2729, grad_fn=<DivBackward0>) ; epoch time:  0.16927385330200195\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 33}\n",
      "Epoch:  34\n",
      "Avg loss:  tensor(0.3368, grad_fn=<DivBackward0>) ; epoch time:  0.1662006378173828\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 34}\n",
      "Epoch:  35\n",
      "Avg loss:  tensor(0.3217, grad_fn=<DivBackward0>) ; epoch time:  0.16347646713256836\n",
      "Train  accuracy: 0.85\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 35}\n",
      "Epoch:  36\n",
      "Avg loss:  tensor(0.3222, grad_fn=<DivBackward0>) ; epoch time:  0.17130756378173828\n",
      "Train  accuracy: 0.8333333333333334\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 36}\n",
      "Epoch:  37\n",
      "Avg loss:  tensor(0.2609, grad_fn=<DivBackward0>) ; epoch time:  0.1722424030303955\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 37}\n",
      "Epoch:  38\n",
      "Avg loss:  tensor(0.3049, grad_fn=<DivBackward0>) ; epoch time:  0.16912364959716797\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 38}\n",
      "Epoch:  39\n",
      "Avg loss:  tensor(0.2620, grad_fn=<DivBackward0>) ; epoch time:  0.15971612930297852\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 39}\n",
      "Epoch:  40\n",
      "Avg loss:  tensor(0.2761, grad_fn=<DivBackward0>) ; epoch time:  0.16823315620422363\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 40}\n",
      "Epoch:  41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.2608, grad_fn=<DivBackward0>) ; epoch time:  0.1664581298828125\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 41}\n",
      "Epoch:  42\n",
      "Avg loss:  tensor(0.2445, grad_fn=<DivBackward0>) ; epoch time:  0.2072620391845703\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 42}\n",
      "Epoch:  43\n",
      "Avg loss:  tensor(0.2843, grad_fn=<DivBackward0>) ; epoch time:  0.167769193649292\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 43}\n",
      "Epoch:  44\n",
      "Avg loss:  tensor(0.2289, grad_fn=<DivBackward0>) ; epoch time:  0.16641545295715332\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 44}\n",
      "Epoch:  45\n",
      "Avg loss:  tensor(0.2878, grad_fn=<DivBackward0>) ; epoch time:  0.17108917236328125\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 45}\n",
      "Epoch:  46\n",
      "Avg loss:  tensor(0.2449, grad_fn=<DivBackward0>) ; epoch time:  0.1705789566040039\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 46}\n",
      "Epoch:  47\n",
      "Avg loss:  tensor(0.3687, grad_fn=<DivBackward0>) ; epoch time:  0.16945862770080566\n",
      "Train  accuracy: 0.8583333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 47}\n",
      "Epoch:  48\n",
      "Avg loss:  tensor(0.2546, grad_fn=<DivBackward0>) ; epoch time:  0.16271018981933594\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 48}\n",
      "Epoch:  49\n",
      "Avg loss:  tensor(0.2594, grad_fn=<DivBackward0>) ; epoch time:  0.171156644821167\n",
      "Train  accuracy: 0.8583333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 49}\n",
      "Epoch:  50\n",
      "Avg loss:  tensor(0.2482, grad_fn=<DivBackward0>) ; epoch time:  0.1683340072631836\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 50}\n",
      "Epoch:  51\n",
      "Avg loss:  tensor(0.2361, grad_fn=<DivBackward0>) ; epoch time:  0.167921781539917\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 51}\n",
      "Epoch:  52\n",
      "Avg loss:  tensor(0.2391, grad_fn=<DivBackward0>) ; epoch time:  0.17151284217834473\n",
      "Train  accuracy: 0.8416666666666667\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 52}\n",
      "Epoch:  53\n",
      "Avg loss:  tensor(0.3145, grad_fn=<DivBackward0>) ; epoch time:  0.23582005500793457\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 53}\n",
      "Epoch:  54\n",
      "Avg loss:  tensor(0.2542, grad_fn=<DivBackward0>) ; epoch time:  0.17036008834838867\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 54}\n",
      "Epoch:  55\n",
      "Avg loss:  tensor(0.2432, grad_fn=<DivBackward0>) ; epoch time:  0.16821980476379395\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 55}\n",
      "Epoch:  56\n",
      "Avg loss:  tensor(0.2597, grad_fn=<DivBackward0>) ; epoch time:  0.1676466464996338\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 56}\n",
      "Epoch:  57\n",
      "Avg loss:  tensor(0.2709, grad_fn=<DivBackward0>) ; epoch time:  0.17171359062194824\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 57}\n",
      "Epoch:  58\n",
      "Avg loss:  tensor(0.2427, grad_fn=<DivBackward0>) ; epoch time:  0.17026758193969727\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 58}\n",
      "Epoch:  59\n",
      "Avg loss:  tensor(0.2291, grad_fn=<DivBackward0>) ; epoch time:  0.1674661636352539\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 59}\n",
      "Epoch:  60\n",
      "Avg loss:  tensor(0.2553, grad_fn=<DivBackward0>) ; epoch time:  0.16913652420043945\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 60}\n",
      "Epoch:  61\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.2414, grad_fn=<DivBackward0>) ; epoch time:  0.1734790802001953\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 61}\n",
      "Epoch:  62\n",
      "Avg loss:  tensor(0.2131, grad_fn=<DivBackward0>) ; epoch time:  0.1714630126953125\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 62}\n",
      "Epoch:  63\n",
      "Avg loss:  tensor(0.2316, grad_fn=<DivBackward0>) ; epoch time:  0.17334556579589844\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 63}\n",
      "Epoch:  64\n",
      "Avg loss:  tensor(0.2018, grad_fn=<DivBackward0>) ; epoch time:  0.1736156940460205\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 64}\n",
      "Epoch:  65\n",
      "Avg loss:  tensor(0.1910, grad_fn=<DivBackward0>) ; epoch time:  0.17188692092895508\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 65}\n",
      "Epoch:  66\n",
      "Avg loss:  tensor(0.2317, grad_fn=<DivBackward0>) ; epoch time:  0.16895246505737305\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 66}\n",
      "Epoch:  67\n",
      "Avg loss:  tensor(0.2198, grad_fn=<DivBackward0>) ; epoch time:  0.1691126823425293\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 67}\n",
      "Epoch:  68\n",
      "Avg loss:  tensor(0.2441, grad_fn=<DivBackward0>) ; epoch time:  0.16822052001953125\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 68}\n",
      "Epoch:  69\n",
      "Avg loss:  tensor(0.1874, grad_fn=<DivBackward0>) ; epoch time:  0.19567418098449707\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 69}\n",
      "Epoch:  70\n",
      "Avg loss:  tensor(0.2530, grad_fn=<DivBackward0>) ; epoch time:  0.16938471794128418\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 70}\n",
      "Epoch:  71\n",
      "Avg loss:  tensor(0.2484, grad_fn=<DivBackward0>) ; epoch time:  0.16002964973449707\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 71}\n",
      "Epoch:  72\n",
      "Avg loss:  tensor(0.2102, grad_fn=<DivBackward0>) ; epoch time:  0.15889763832092285\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 72}\n",
      "Epoch:  73\n",
      "Avg loss:  tensor(0.1965, grad_fn=<DivBackward0>) ; epoch time:  0.15776276588439941\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 73}\n",
      "Epoch:  74\n",
      "Avg loss:  tensor(0.2378, grad_fn=<DivBackward0>) ; epoch time:  0.1603684425354004\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 74}\n",
      "Epoch:  75\n",
      "Avg loss:  tensor(0.3391, grad_fn=<DivBackward0>) ; epoch time:  0.1739795207977295\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 75}\n",
      "Epoch:  76\n",
      "Avg loss:  tensor(0.2088, grad_fn=<DivBackward0>) ; epoch time:  0.16208481788635254\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 76}\n",
      "Epoch:  77\n",
      "Avg loss:  tensor(0.2103, grad_fn=<DivBackward0>) ; epoch time:  0.15943384170532227\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 77}\n",
      "Epoch:  78\n",
      "Avg loss:  tensor(0.2314, grad_fn=<DivBackward0>) ; epoch time:  0.16133570671081543\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 78}\n",
      "Epoch:  79\n",
      "Avg loss:  tensor(0.2214, grad_fn=<DivBackward0>) ; epoch time:  0.1599583625793457\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 79}\n",
      "Epoch:  80\n",
      "Avg loss:  tensor(0.2202, grad_fn=<DivBackward0>) ; epoch time:  0.15910768508911133\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 80}\n",
      "Epoch:  81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.2448, grad_fn=<DivBackward0>) ; epoch time:  0.1585404872894287\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 81}\n",
      "Epoch:  82\n",
      "Avg loss:  tensor(0.2364, grad_fn=<DivBackward0>) ; epoch time:  0.15751266479492188\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 82}\n",
      "Epoch:  83\n",
      "Avg loss:  tensor(0.1790, grad_fn=<DivBackward0>) ; epoch time:  0.16297030448913574\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 83}\n",
      "Epoch:  84\n",
      "Avg loss:  tensor(0.1628, grad_fn=<DivBackward0>) ; epoch time:  0.15922999382019043\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 84}\n",
      "Epoch:  85\n",
      "Avg loss:  tensor(0.1995, grad_fn=<DivBackward0>) ; epoch time:  0.15943503379821777\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 85}\n",
      "Epoch:  86\n",
      "Avg loss:  tensor(0.1928, grad_fn=<DivBackward0>) ; epoch time:  0.15856552124023438\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 86}\n",
      "Epoch:  87\n",
      "Avg loss:  tensor(0.2148, grad_fn=<DivBackward0>) ; epoch time:  0.15928959846496582\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 87}\n",
      "Epoch:  88\n",
      "Avg loss:  tensor(0.1785, grad_fn=<DivBackward0>) ; epoch time:  0.1605527400970459\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 88}\n",
      "Epoch:  89\n",
      "Avg loss:  tensor(0.1659, grad_fn=<DivBackward0>) ; epoch time:  0.15927886962890625\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 89}\n",
      "Epoch:  90\n",
      "Avg loss:  tensor(0.2109, grad_fn=<DivBackward0>) ; epoch time:  0.1599891185760498\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 90}\n",
      "Epoch:  91\n",
      "Avg loss:  tensor(0.2082, grad_fn=<DivBackward0>) ; epoch time:  0.15778470039367676\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 91}\n",
      "Epoch:  92\n",
      "Avg loss:  tensor(0.1848, grad_fn=<DivBackward0>) ; epoch time:  0.18734192848205566\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 92}\n",
      "Epoch:  93\n",
      "Avg loss:  tensor(0.2169, grad_fn=<DivBackward0>) ; epoch time:  0.16272926330566406\n",
      "Train  accuracy: 0.8583333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 93}\n",
      "Epoch:  94\n",
      "Avg loss:  tensor(0.1588, grad_fn=<DivBackward0>) ; epoch time:  0.15912246704101562\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 94}\n",
      "Epoch:  95\n",
      "Avg loss:  tensor(0.2462, grad_fn=<DivBackward0>) ; epoch time:  0.1600205898284912\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 95}\n",
      "Epoch:  96\n",
      "Avg loss:  tensor(0.1993, grad_fn=<DivBackward0>) ; epoch time:  0.1587822437286377\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 96}\n",
      "Epoch:  97\n",
      "Avg loss:  tensor(0.1744, grad_fn=<DivBackward0>) ; epoch time:  0.1624314785003662\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 97}\n",
      "Epoch:  98\n",
      "Avg loss:  tensor(0.2445, grad_fn=<DivBackward0>) ; epoch time:  0.16631174087524414\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 98}\n",
      "Epoch:  99\n",
      "Avg loss:  tensor(0.2092, grad_fn=<DivBackward0>) ; epoch time:  0.1607964038848877\n",
      "Train  accuracy: 0.875\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 99}\n",
      "Epoch:  100\n",
      "Avg loss:  tensor(0.1805, grad_fn=<DivBackward0>) ; epoch time:  0.15945100784301758\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 100}\n",
      "Epoch:  101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.1712, grad_fn=<DivBackward0>) ; epoch time:  0.15716266632080078\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 101}\n",
      "Epoch:  102\n",
      "Avg loss:  tensor(0.1706, grad_fn=<DivBackward0>) ; epoch time:  0.16378426551818848\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 102}\n",
      "Epoch:  103\n",
      "Avg loss:  tensor(0.1981, grad_fn=<DivBackward0>) ; epoch time:  0.16050982475280762\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 103}\n",
      "Epoch:  104\n",
      "Avg loss:  tensor(0.1717, grad_fn=<DivBackward0>) ; epoch time:  0.16109585762023926\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 104}\n",
      "Epoch:  105\n",
      "Avg loss:  tensor(0.1907, grad_fn=<DivBackward0>) ; epoch time:  0.16241025924682617\n",
      "Train  accuracy: 0.8666666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 105}\n",
      "Epoch:  106\n",
      "Avg loss:  tensor(0.2300, grad_fn=<DivBackward0>) ; epoch time:  0.1603555679321289\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 106}\n",
      "Epoch:  107\n",
      "Avg loss:  tensor(0.1636, grad_fn=<DivBackward0>) ; epoch time:  0.15953946113586426\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 107}\n",
      "Epoch:  108\n",
      "Avg loss:  tensor(0.2102, grad_fn=<DivBackward0>) ; epoch time:  0.15720272064208984\n",
      "Train  accuracy: 0.9\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 108}\n",
      "Epoch:  109\n",
      "Avg loss:  tensor(0.1608, grad_fn=<DivBackward0>) ; epoch time:  0.20919370651245117\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 109}\n",
      "Epoch:  110\n",
      "Avg loss:  tensor(0.2083, grad_fn=<DivBackward0>) ; epoch time:  0.16510462760925293\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 110}\n",
      "Epoch:  111\n",
      "Avg loss:  tensor(0.1500, grad_fn=<DivBackward0>) ; epoch time:  0.16057729721069336\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 111}\n",
      "Epoch:  112\n",
      "Avg loss:  tensor(0.2178, grad_fn=<DivBackward0>) ; epoch time:  0.15883398056030273\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 112}\n",
      "Epoch:  113\n",
      "Avg loss:  tensor(0.1750, grad_fn=<DivBackward0>) ; epoch time:  0.15988373756408691\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 113}\n",
      "Epoch:  114\n",
      "Avg loss:  tensor(0.2817, grad_fn=<DivBackward0>) ; epoch time:  0.16003131866455078\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7777777777777778, 'recall': 0.8571428571428572, 'acc': 0.7894736842105263, 'epoch': 114}\n",
      "Epoch:  115\n",
      "Avg loss:  tensor(0.1997, grad_fn=<DivBackward0>) ; epoch time:  0.15899896621704102\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 115}\n",
      "Epoch:  116\n",
      "Avg loss:  tensor(0.1817, grad_fn=<DivBackward0>) ; epoch time:  0.15737628936767578\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 116}\n",
      "Epoch:  117\n",
      "Avg loss:  tensor(0.1988, grad_fn=<DivBackward0>) ; epoch time:  0.16016459465026855\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 117}\n",
      "Epoch:  118\n",
      "Avg loss:  tensor(0.1764, grad_fn=<DivBackward0>) ; epoch time:  0.15920090675354004\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 118}\n",
      "Epoch:  119\n",
      "Avg loss:  tensor(0.1909, grad_fn=<DivBackward0>) ; epoch time:  0.1575150489807129\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 119}\n",
      "Epoch:  120\n",
      "Avg loss:  tensor(0.1505, grad_fn=<DivBackward0>) ; epoch time:  0.16035962104797363\n",
      "Train  accuracy: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 120}\n",
      "Epoch:  121\n",
      "Avg loss:  tensor(0.1774, grad_fn=<DivBackward0>) ; epoch time:  0.15867328643798828\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 121}\n",
      "Epoch:  122\n",
      "Avg loss:  tensor(0.1805, grad_fn=<DivBackward0>) ; epoch time:  0.15909957885742188\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 122}\n",
      "Epoch:  123\n",
      "Avg loss:  tensor(0.1478, grad_fn=<DivBackward0>) ; epoch time:  0.15906381607055664\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 123}\n",
      "Epoch:  124\n",
      "Avg loss:  tensor(0.1687, grad_fn=<DivBackward0>) ; epoch time:  0.16019797325134277\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 124}\n",
      "Epoch:  125\n",
      "Avg loss:  tensor(0.2083, grad_fn=<DivBackward0>) ; epoch time:  0.15848374366760254\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 125}\n",
      "Epoch:  126\n",
      "Avg loss:  tensor(0.1490, grad_fn=<DivBackward0>) ; epoch time:  0.21499323844909668\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 126}\n",
      "Epoch:  127\n",
      "Avg loss:  tensor(0.1834, grad_fn=<DivBackward0>) ; epoch time:  0.16185498237609863\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 127}\n",
      "Epoch:  128\n",
      "Avg loss:  tensor(0.1684, grad_fn=<DivBackward0>) ; epoch time:  0.16075611114501953\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 128}\n",
      "Epoch:  129\n",
      "Avg loss:  tensor(0.1590, grad_fn=<DivBackward0>) ; epoch time:  0.16011810302734375\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 129}\n",
      "Epoch:  130\n",
      "Avg loss:  tensor(0.1573, grad_fn=<DivBackward0>) ; epoch time:  0.16029024124145508\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 130}\n",
      "Epoch:  131\n",
      "Avg loss:  tensor(0.1809, grad_fn=<DivBackward0>) ; epoch time:  0.15965986251831055\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 131}\n",
      "Epoch:  132\n",
      "Avg loss:  tensor(0.1831, grad_fn=<DivBackward0>) ; epoch time:  0.1584796905517578\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 132}\n",
      "Epoch:  133\n",
      "Avg loss:  tensor(0.1992, grad_fn=<DivBackward0>) ; epoch time:  0.1632850170135498\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 133}\n",
      "Epoch:  134\n",
      "Avg loss:  tensor(0.1995, grad_fn=<DivBackward0>) ; epoch time:  0.20027875900268555\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 134}\n",
      "Epoch:  135\n",
      "Avg loss:  tensor(0.3239, grad_fn=<DivBackward0>) ; epoch time:  0.1732022762298584\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 135}\n",
      "Epoch:  136\n",
      "Avg loss:  tensor(0.1730, grad_fn=<DivBackward0>) ; epoch time:  0.16021466255187988\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 136}\n",
      "Epoch:  137\n",
      "Avg loss:  tensor(0.2024, grad_fn=<DivBackward0>) ; epoch time:  0.16296958923339844\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 137}\n",
      "Epoch:  138\n",
      "Avg loss:  tensor(0.1733, grad_fn=<DivBackward0>) ; epoch time:  0.16074180603027344\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 138}\n",
      "Epoch:  139\n",
      "Avg loss:  tensor(0.2826, grad_fn=<DivBackward0>) ; epoch time:  0.18499135971069336\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 139}\n",
      "Epoch:  140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.1440, grad_fn=<DivBackward0>) ; epoch time:  0.16183876991271973\n",
      "Train  accuracy: 0.9666666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 140}\n",
      "Epoch:  141\n",
      "Avg loss:  tensor(0.1430, grad_fn=<DivBackward0>) ; epoch time:  0.1624140739440918\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 141}\n",
      "Epoch:  142\n",
      "Avg loss:  tensor(0.2037, grad_fn=<DivBackward0>) ; epoch time:  0.1600797176361084\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 142}\n",
      "Epoch:  143\n",
      "Avg loss:  tensor(0.2065, grad_fn=<DivBackward0>) ; epoch time:  0.15990495681762695\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 143}\n",
      "Epoch:  144\n",
      "Avg loss:  tensor(0.1781, grad_fn=<DivBackward0>) ; epoch time:  0.16257643699645996\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 144}\n",
      "Epoch:  145\n",
      "Avg loss:  tensor(0.1889, grad_fn=<DivBackward0>) ; epoch time:  0.16296720504760742\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 145}\n",
      "Epoch:  146\n",
      "Avg loss:  tensor(0.2128, grad_fn=<DivBackward0>) ; epoch time:  0.15873980522155762\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 146}\n",
      "Epoch:  147\n",
      "Avg loss:  tensor(0.1427, grad_fn=<DivBackward0>) ; epoch time:  0.16135740280151367\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 147}\n",
      "Epoch:  148\n",
      "Avg loss:  tensor(0.1692, grad_fn=<DivBackward0>) ; epoch time:  0.15983176231384277\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 148}\n",
      "Epoch:  149\n",
      "Avg loss:  tensor(0.2152, grad_fn=<DivBackward0>) ; epoch time:  0.15952634811401367\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 149}\n",
      "Epoch:  150\n",
      "Avg loss:  tensor(0.2336, grad_fn=<DivBackward0>) ; epoch time:  0.16652226448059082\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 150}\n",
      "Epoch:  151\n",
      "Avg loss:  tensor(0.1697, grad_fn=<DivBackward0>) ; epoch time:  0.16240477561950684\n",
      "Train  accuracy: 0.9166666666666666\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 151}\n",
      "Epoch:  152\n",
      "Avg loss:  tensor(0.1866, grad_fn=<DivBackward0>) ; epoch time:  0.15939903259277344\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 152}\n",
      "Epoch:  153\n",
      "Avg loss:  tensor(0.1602, grad_fn=<DivBackward0>) ; epoch time:  0.15970587730407715\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 153}\n",
      "Epoch:  154\n",
      "Avg loss:  tensor(0.1604, grad_fn=<DivBackward0>) ; epoch time:  0.16200470924377441\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 154}\n",
      "Epoch:  155\n",
      "Avg loss:  tensor(0.1281, grad_fn=<DivBackward0>) ; epoch time:  0.16132831573486328\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 155}\n",
      "Epoch:  156\n",
      "Avg loss:  tensor(0.2067, grad_fn=<DivBackward0>) ; epoch time:  0.2035534381866455\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 156}\n",
      "Epoch:  157\n",
      "Avg loss:  tensor(0.1703, grad_fn=<DivBackward0>) ; epoch time:  0.16258811950683594\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 157}\n",
      "Epoch:  158\n",
      "Avg loss:  tensor(0.2180, grad_fn=<DivBackward0>) ; epoch time:  0.1629037857055664\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7045454545454546, 'recall': 0.7571428571428571, 'acc': 0.7368421052631579, 'epoch': 158}\n",
      "Epoch:  159\n",
      "Avg loss:  tensor(0.1522, grad_fn=<DivBackward0>) ; epoch time:  0.1616814136505127\n",
      "Train  accuracy: 0.8833333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 159}\n",
      "Epoch:  160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.1585, grad_fn=<DivBackward0>) ; epoch time:  0.15954160690307617\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 160}\n",
      "Epoch:  161\n",
      "Avg loss:  tensor(0.1829, grad_fn=<DivBackward0>) ; epoch time:  0.16056132316589355\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 161}\n",
      "Epoch:  162\n",
      "Avg loss:  tensor(0.1363, grad_fn=<DivBackward0>) ; epoch time:  0.16110754013061523\n",
      "Train  accuracy: 0.975\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 162}\n",
      "Epoch:  163\n",
      "Avg loss:  tensor(0.1934, grad_fn=<DivBackward0>) ; epoch time:  0.1601276397705078\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 163}\n",
      "Epoch:  164\n",
      "Avg loss:  tensor(0.1690, grad_fn=<DivBackward0>) ; epoch time:  0.16155385971069336\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 164}\n",
      "Epoch:  165\n",
      "Avg loss:  tensor(0.2101, grad_fn=<DivBackward0>) ; epoch time:  0.16207242012023926\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 165}\n",
      "Epoch:  166\n",
      "Avg loss:  tensor(0.1671, grad_fn=<DivBackward0>) ; epoch time:  0.16035771369934082\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 166}\n",
      "Epoch:  167\n",
      "Avg loss:  tensor(0.1579, grad_fn=<DivBackward0>) ; epoch time:  0.20343756675720215\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 167}\n",
      "Epoch:  168\n",
      "Avg loss:  tensor(0.1578, grad_fn=<DivBackward0>) ; epoch time:  0.16225457191467285\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 168}\n",
      "Epoch:  169\n",
      "Avg loss:  tensor(0.1328, grad_fn=<DivBackward0>) ; epoch time:  0.16046571731567383\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 169}\n",
      "Epoch:  170\n",
      "Avg loss:  tensor(0.1365, grad_fn=<DivBackward0>) ; epoch time:  0.16003751754760742\n",
      "Train  accuracy: 0.9083333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 170}\n",
      "Epoch:  171\n",
      "Avg loss:  tensor(0.1891, grad_fn=<DivBackward0>) ; epoch time:  0.16089081764221191\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 171}\n",
      "Epoch:  172\n",
      "Avg loss:  tensor(0.2045, grad_fn=<DivBackward0>) ; epoch time:  0.16139650344848633\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 172}\n",
      "Epoch:  173\n",
      "Avg loss:  tensor(0.1653, grad_fn=<DivBackward0>) ; epoch time:  0.17028284072875977\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 173}\n",
      "Epoch:  174\n",
      "Avg loss:  tensor(0.1107, grad_fn=<DivBackward0>) ; epoch time:  0.1597447395324707\n",
      "Train  accuracy: 0.9666666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 174}\n",
      "Epoch:  175\n",
      "Avg loss:  tensor(0.1894, grad_fn=<DivBackward0>) ; epoch time:  0.15962719917297363\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 175}\n",
      "Epoch:  176\n",
      "Avg loss:  tensor(0.1472, grad_fn=<DivBackward0>) ; epoch time:  0.15971040725708008\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 176}\n",
      "Epoch:  177\n",
      "Avg loss:  tensor(0.1276, grad_fn=<DivBackward0>) ; epoch time:  0.16062521934509277\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 177}\n",
      "Epoch:  178\n",
      "Avg loss:  tensor(0.2391, grad_fn=<DivBackward0>) ; epoch time:  0.1603243350982666\n",
      "Train  accuracy: 0.8916666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 178}\n",
      "Epoch:  179\n",
      "Avg loss:  tensor(0.1090, grad_fn=<DivBackward0>) ; epoch time:  0.16061806678771973\n",
      "Train  accuracy: 0.9416666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7045454545454546, 'recall': 0.7571428571428571, 'acc': 0.7368421052631579, 'epoch': 179}\n",
      "Epoch:  180\n",
      "Avg loss:  tensor(0.1731, grad_fn=<DivBackward0>) ; epoch time:  0.1602787971496582\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 180}\n",
      "Epoch:  181\n",
      "Avg loss:  tensor(0.1508, grad_fn=<DivBackward0>) ; epoch time:  0.16160011291503906\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 181}\n",
      "Epoch:  182\n",
      "Avg loss:  tensor(0.2003, grad_fn=<DivBackward0>) ; epoch time:  0.159653902053833\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.6842105263157895\n",
      "Test  accuracy: 0.7368421052631579\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7045454545454546, 'recall': 0.7571428571428571, 'acc': 0.7368421052631579, 'epoch': 182}\n",
      "Epoch:  183\n",
      "Avg loss:  tensor(0.2231, grad_fn=<DivBackward0>) ; epoch time:  0.1611170768737793\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 183}\n",
      "Epoch:  184\n",
      "Avg loss:  tensor(0.1468, grad_fn=<DivBackward0>) ; epoch time:  0.18256139755249023\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 184}\n",
      "Epoch:  185\n",
      "Avg loss:  tensor(0.1372, grad_fn=<DivBackward0>) ; epoch time:  0.16097259521484375\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 185}\n",
      "Epoch:  186\n",
      "Avg loss:  tensor(0.1273, grad_fn=<DivBackward0>) ; epoch time:  0.16402053833007812\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 186}\n",
      "Epoch:  187\n",
      "Avg loss:  tensor(0.1519, grad_fn=<DivBackward0>) ; epoch time:  0.15940213203430176\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 187}\n",
      "Epoch:  188\n",
      "Avg loss:  tensor(0.1625, grad_fn=<DivBackward0>) ; epoch time:  0.16316437721252441\n",
      "Train  accuracy: 0.9666666666666667\n",
      "Validation  accuracy: 0.7894736842105263\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 188}\n",
      "Epoch:  189\n",
      "Avg loss:  tensor(0.1156, grad_fn=<DivBackward0>) ; epoch time:  0.16119980812072754\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 189}\n",
      "Epoch:  190\n",
      "Avg loss:  tensor(0.1372, grad_fn=<DivBackward0>) ; epoch time:  0.17011737823486328\n",
      "Train  accuracy: 0.95\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 190}\n",
      "Epoch:  191\n",
      "Avg loss:  tensor(0.1268, grad_fn=<DivBackward0>) ; epoch time:  0.16074585914611816\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 191}\n",
      "Epoch:  192\n",
      "Avg loss:  tensor(0.2196, grad_fn=<DivBackward0>) ; epoch time:  0.16249656677246094\n",
      "Train  accuracy: 0.9583333333333334\n",
      "Validation  accuracy: 0.7368421052631579\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 192}\n",
      "Epoch:  193\n",
      "Avg loss:  tensor(0.1345, grad_fn=<DivBackward0>) ; epoch time:  0.16068243980407715\n",
      "Train  accuracy: 0.925\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 193}\n",
      "Epoch:  194\n",
      "Avg loss:  tensor(0.2441, grad_fn=<DivBackward0>) ; epoch time:  0.16050481796264648\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 194}\n",
      "Epoch:  195\n",
      "Avg loss:  tensor(0.1390, grad_fn=<DivBackward0>) ; epoch time:  0.16277742385864258\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 195}\n",
      "Epoch:  196\n",
      "Avg loss:  tensor(0.1808, grad_fn=<DivBackward0>) ; epoch time:  0.15987181663513184\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 196}\n",
      "Epoch:  197\n",
      "Avg loss:  tensor(0.1869, grad_fn=<DivBackward0>) ; epoch time:  0.1577897071838379\n",
      "Train  accuracy: 0.9416666666666667\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 197}\n",
      "Epoch:  198\n",
      "Avg loss:  tensor(0.3342, grad_fn=<DivBackward0>) ; epoch time:  0.16008639335632324\n",
      "Train  accuracy: 0.9666666666666667\n",
      "Validation  accuracy: 0.631578947368421\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 198}\n",
      "Epoch:  199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg loss:  tensor(0.1724, grad_fn=<DivBackward0>) ; epoch time:  0.15971946716308594\n",
      "Train  accuracy: 0.9333333333333333\n",
      "Validation  accuracy: 0.8421052631578947\n",
      "Test  accuracy: 0.7894736842105263\n",
      "Best val result:  {'epoch': 8, 'loss': tensor(0.3435, grad_fn=<DivBackward0>), 'acc': 0.8947368421052632}\n",
      "Test result:  {'prec': 0.7440476190476191, 'recall': 0.7928571428571429, 'acc': 0.7894736842105263, 'epoch': 199}\n",
      "torch.Size([150, 28, 28]) torch.Size([150, 28, 7]) torch.Size([150])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_dim, hidden_dim, embedding_dim, label_dim, num_layers = 7, 20, 20, 2, 3\n",
    "\n",
    "same_feat=True\n",
    "writer=None\n",
    "mask_nodes=True\n",
    "\n",
    "model = GcnEncoderGraph(input_dim, hidden_dim, embedding_dim, label_dim, num_layers, args=args)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model.parameters()), lr=0.001\n",
    ")\n",
    "iter = 0\n",
    "best_val_result = {\"epoch\": 0, \"loss\": 0, \"acc\": 0}\n",
    "test_result = {\"epoch\": 0, \"loss\": 0, \"acc\": 0}\n",
    "train_accs = []\n",
    "train_epochs = []\n",
    "best_val_accs = []\n",
    "best_val_epochs = []\n",
    "test_accs = []\n",
    "test_epochs = []\n",
    "val_accs = []\n",
    "\n",
    "for epoch in range(args.num_epochs):\n",
    "    begin_time = time.time()\n",
    "    avg_loss = 0.0\n",
    "    model.train()\n",
    "    predictions = []\n",
    "    print(\"Epoch: \", epoch)\n",
    "    for batch_idx, data in enumerate(train_dataset):\n",
    "        model.zero_grad()\n",
    "        if batch_idx == 0:\n",
    "            prev_adjs = data[\"adj\"]\n",
    "            prev_feats = data[\"feats\"]\n",
    "            prev_labels = data[\"label\"]\n",
    "            all_adjs = prev_adjs\n",
    "            all_feats = prev_feats\n",
    "            all_labels = prev_labels\n",
    "        elif batch_idx < 20:\n",
    "            prev_adjs = data[\"adj\"]\n",
    "            prev_feats = data[\"feats\"]\n",
    "            prev_labels = data[\"label\"]\n",
    "            all_adjs = torch.cat((all_adjs, prev_adjs), dim=0)\n",
    "            all_feats = torch.cat((all_feats, prev_feats), dim=0)\n",
    "            all_labels = torch.cat((all_labels, prev_labels), dim=0)\n",
    "            \n",
    "        if args.gpu:\n",
    "            adj = Variable(data[\"adj\"].float(), requires_grad=False).cuda()\n",
    "            h0 = Variable(data[\"feats\"].float(), requires_grad=False).cuda()\n",
    "            label = Variable(data[\"label\"].long()).cuda()\n",
    "            batch_num_nodes = data[\"num_nodes\"].int().numpy() if mask_nodes else None\n",
    "            assign_input = Variable(\n",
    "                data[\"assign_feats\"].float(), requires_grad=False\n",
    "            ).cuda()\n",
    "            \n",
    "        else:\n",
    "            adj = Variable(data[\"adj\"].float(), requires_grad=False)\n",
    "            h0 = Variable(data[\"feats\"].float(), requires_grad=False)\n",
    "            label = Variable(data[\"label\"].long())\n",
    "            batch_num_nodes = data[\"num_nodes\"].int().numpy() if mask_nodes else None\n",
    "            assign_input = Variable(\n",
    "                data[\"assign_feats\"].float(), requires_grad=False\n",
    "            )\n",
    "\n",
    "        edge_index = []\n",
    "        for a in adj:\n",
    "            edge_index.append(from_adj_to_edge_index(a))\n",
    "        \n",
    "        ypred = model(h0, edge_index, batch_num_nodes, assign_x=assign_input)\n",
    "        #ypred, att_adj = model(h0, adj, batch_num_nodes, assign_x=assign_input)\n",
    "        if batch_idx < 5:\n",
    "            predictions += ypred.cpu().detach().numpy().tolist()\n",
    "\n",
    "        if not args.method == \"soft-assign\" or not args.linkpred:\n",
    "            loss = model.loss(ypred, label)\n",
    "        else:\n",
    "            loss = model.loss(ypred, label, adj, batch_num_nodes)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm(model.parameters(), args.clip)\n",
    "        optimizer.step()\n",
    "        iter += 1\n",
    "        avg_loss += loss\n",
    "\n",
    "    avg_loss /= batch_idx + 1\n",
    "    elapsed = time.time() - begin_time\n",
    "    print(\"Avg loss: \", avg_loss, \"; epoch time: \", elapsed)\n",
    "    \n",
    "    result = evaluate(train_dataset, model, args, name=\"Train\", max_num_examples=100)\n",
    "    train_accs.append(result[\"acc\"])\n",
    "    train_epochs.append(epoch)\n",
    "    if val_dataset is not None:\n",
    "        val_result = evaluate(val_dataset, model, args, name=\"Validation\")\n",
    "        val_accs.append(val_result[\"acc\"])\n",
    "    if val_result[\"acc\"] > best_val_result[\"acc\"] - 1e-7:\n",
    "        best_val_result[\"acc\"] = val_result[\"acc\"]\n",
    "        best_val_result[\"epoch\"] = epoch\n",
    "        best_val_result[\"loss\"] = avg_loss\n",
    "    if test_dataset is not None:\n",
    "        test_result = evaluate(test_dataset, model, args, name=\"Test\")\n",
    "        test_result[\"epoch\"] = epoch\n",
    "    print(\"Best val result: \", best_val_result)\n",
    "    best_val_epochs.append(best_val_result[\"epoch\"])\n",
    "    best_val_accs.append(best_val_result[\"acc\"])\n",
    "    if test_dataset is not None:\n",
    "        print(\"Test result: \", test_result)\n",
    "        test_epochs.append(test_result[\"epoch\"])\n",
    "        test_accs.append(test_result[\"acc\"])\n",
    "\n",
    "matplotlib.style.use(\"seaborn\")\n",
    "plt.switch_backend(\"agg\")\n",
    "plt.figure()\n",
    "plt.plot(train_epochs, math_utils.exp_moving_avg(train_accs, 0.85), \"-\", lw=1)\n",
    "if test_dataset is not None:\n",
    "    plt.plot(best_val_epochs, best_val_accs, \"bo\", test_epochs, test_accs, \"go\")\n",
    "    plt.legend([\"train\", \"val\", \"test\"])\n",
    "else:\n",
    "    plt.plot(best_val_epochs, best_val_accs, \"bo\")\n",
    "    plt.legend([\"train\", \"val\"])\n",
    "#plt.savefig(io_utils.gen_train_plt_name(args), dpi=600)\n",
    "#plt.close()\n",
    "matplotlib.style.use(\"default\")\n",
    "\n",
    "print(all_adjs.shape, all_feats.shape, all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train  accuracy: 0.925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prec': 0.9239409499358151, 'recall': 0.9078419265205311, 'acc': 0.925}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = evaluate(train_dataset, model, args, name=\"Train\", max_num_examples=100)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  accuracy: 0.7894736842105263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prec': 0.7440476190476191,\n",
       " 'recall': 0.7928571428571429,\n",
       " 'acc': 0.7894736842105263}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = evaluate(test_dataset, model, args, name=\"Test\", max_num_examples=100)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import GNNExplainer\n",
    "from tqdm import tqdm\n",
    "from scipy.special import softmax\n",
    "\n",
    "EPS = 1e-15\n",
    "\n",
    "\n",
    "class TargetedGNNExplainer(GNNExplainer):\n",
    "    def __loss__(self, node_idx, log_logits, target_class):\n",
    "        loss = -log_logits[node_idx, target_class]\n",
    "\n",
    "        m = self.edge_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['edge_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['edge_ent'] * ent.mean()\n",
    "\n",
    "\n",
    "        m = self.node_feat_mask.sigmoid()\n",
    "        loss = loss + self.coeffs['node_feat_size'] * m.sum()\n",
    "        ent = -m * torch.log(m + EPS) - (1 - m) * torch.log(1 - m + EPS)\n",
    "        loss = loss + self.coeffs['node_feat_ent'] * ent.mean()\n",
    "\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def explain_graph_with_target(self, x, edge_index, target, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for a graph.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        # all nodes belong to same graph\n",
    "        batch = torch.zeros(x.shape[0], dtype=int, device=x.device)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        if target is not None:\n",
    "            with torch.no_grad():\n",
    "                out = self.model(x=x, edge_index=edge_index, batch=batch, **kwargs)\n",
    "                if self.return_type == 'regression':\n",
    "                    prediction = out\n",
    "                else:\n",
    "                    log_logits = self.__to_log_prob__(out)\n",
    "                    pred_label = log_logits.argmax(dim=-1)\n",
    "        else:\n",
    "            if self.return_type == 'regression':\n",
    "                prediction = target\n",
    "            else:\n",
    "                pred_label = target\n",
    "            \n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "        if self.allow_edge_mask:\n",
    "            parameters = [self.node_feat_mask, self.edge_mask]\n",
    "        else:\n",
    "            parameters = [self.node_feat_mask]\n",
    "        optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description('Explain graph')\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            h = x * self.node_feat_mask.sigmoid()\n",
    "            out = self.model(x=h, edge_index=edge_index, batch=batch, **kwargs)\n",
    "            if self.return_type == 'regression':\n",
    "                loss = self.__loss__(-1, out, prediction)\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                loss = self.__loss__(-1, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid().squeeze()\n",
    "        edge_mask = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "        return edge_mask#node_feat_mask, edge_mask\n",
    "\n",
    "    \n",
    "    def explain_node_with_target(self, node_idx, x, edge_index, target, **kwargs):\n",
    "        r\"\"\"Learns and returns a node feature mask and an edge mask that play a\n",
    "        crucial role to explain the prediction made by the GNN for node\n",
    "        :attr:`node_idx`.\n",
    "\n",
    "        Args:\n",
    "            node_idx (int): The node to explain.\n",
    "            x (Tensor): The node feature matrix.\n",
    "            edge_index (LongTensor): The edge indices.\n",
    "            **kwargs (optional): Additional arguments passed to the GNN module.\n",
    "\n",
    "        :rtype: (:class:`Tensor`, :class:`Tensor`)\n",
    "        \"\"\"\n",
    "\n",
    "        self.model.eval()\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        num_nodes = x.size(0)\n",
    "        num_edges = edge_index.size(1)\n",
    "\n",
    "        # Only operate on a k-hop subgraph around `node_idx`.\n",
    "        x, edge_index, mapping, hard_edge_mask, subset, kwargs = \\\n",
    "            self.__subgraph__(node_idx, x, edge_index, **kwargs)\n",
    "\n",
    "        # Get the initial prediction.\n",
    "        # Get the initial prediction.\n",
    "        if target is None:\n",
    "            with torch.no_grad():\n",
    "                out = self.model(x, edge_index)\n",
    "                if self.return_type == 'regression':\n",
    "                    prediction = out\n",
    "                else:\n",
    "                    log_logits = self.__to_log_prob__(out)\n",
    "                    pred_label = log_logits.argmax(dim=-1)\n",
    "        else:\n",
    "            if self.return_type == 'regression':\n",
    "                prediction = target\n",
    "            else:\n",
    "                pred_label = target\n",
    "\n",
    "        self.__set_masks__(x, edge_index)\n",
    "        self.to(x.device)\n",
    "\n",
    "        if self.allow_edge_mask:\n",
    "            parameters = [self.edge_mask]\n",
    "        else:\n",
    "            parameters = [self.node_feat_mask]\n",
    "        optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar = tqdm(total=self.epochs)\n",
    "            pbar.set_description(f'Explain node {node_idx}')\n",
    "\n",
    "        for epoch in range(1, 800):#self.epochs + 1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self.model(x, edge_index)\n",
    "            if self.return_type == 'regression':\n",
    "                loss = self.__loss__(mapping, out, prediction)\n",
    "            else:\n",
    "                log_logits = self.__to_log_prob__(out)\n",
    "                loss = self.__loss__(mapping, log_logits, pred_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if self.log:  # pragma: no cover\n",
    "                pbar.update(1)\n",
    "\n",
    "        if self.log:  # pragma: no cover\n",
    "            pbar.close()\n",
    "\n",
    "\n",
    "        node_feat_mask = self.node_feat_mask.detach().sigmoid()\n",
    "        if self.feat_mask_type == 'individual_feature':\n",
    "            new_mask = x.new_zeros(num_nodes, x.size(-1))\n",
    "            new_mask[subset] = node_feat_mask\n",
    "            node_feat_mask = new_mask\n",
    "        elif self.feat_mask_type == 'scalar':\n",
    "            new_mask = x.new_zeros(num_nodes, 1)\n",
    "            new_mask[subset] = node_feat_mask\n",
    "            node_feat_mask = new_mask\n",
    "        node_feat_mask = node_feat_mask.squeeze()\n",
    "\n",
    "\n",
    "        edge_mask = self.edge_mask.new_zeros(num_edges)\n",
    "        edge_mask[hard_edge_mask] = self.edge_mask.detach().sigmoid()\n",
    "\n",
    "        self.__clear_masks__()\n",
    "\n",
    "        #return node_feat_mask, edge_mask\n",
    "        return edge_mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def explain_gnnexplainer(model, node_idx, x, edge_index, target, device, include_edges=None):\\n    explainer = GNNExplainer(model, num_hops=3)\\n    if node_idx is not None:\\n        _, edge_mask = explainer.explain_node(node_idx, x=x, edge_index=edge_index)#, target=target)\\n    edge_mask = edge_mask.detach().numpy()\\n    return edge_mask'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def explain_gnnexplainer(model, node_idx, x, edge_index, target, device, include_edges=None):\n",
    "    explainer = TargetedGNNExplainer(model, num_hops=3)\n",
    "    if node_idx is not None:\n",
    "        edge_mask = explainer.explain_graph_with_target(x=x, edge_index=edge_index, target=target)\n",
    "    edge_mask = edge_mask.detach().numpy()\n",
    "    return edge_mask\n",
    "\n",
    "#from torch_geometric.nn.models import GNNExplainer\n",
    "\n",
    "\"\"\"def explain_gnnexplainer(model, node_idx, x, edge_index, target, device, include_edges=None):\n",
    "    explainer = GNNExplainer(model, num_hops=3)\n",
    "    if node_idx is not None:\n",
    "        _, edge_mask = explainer.explain_node(node_idx, x=x, edge_index=edge_index)#, target=target)\n",
    "    edge_mask = edge_mask.detach().numpy()\n",
    "    return edge_mask\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explain graph: 100%|| 100/100 [00:00<00:00, 400.92it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 393.55it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 422.97it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 407.60it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 408.13it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 377.22it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 360.59it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 411.11it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 406.06it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 415.20it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 412.22it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 426.51it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 408.37it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 405.62it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 417.14it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 305.31it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 406.64it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 409.08it/s]\n",
      "Explain graph: 100%|| 100/100 [00:00<00:00, 411.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    if max_num_examples is not None:\\n        if (batch_idx + 1) * args.batch_size > max_num_examples:\\n            break'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.nn import GNNExplainer\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "edge_masks = []\n",
    "\n",
    "labels = []\n",
    "preds = []\n",
    "for batch_idx, data in enumerate(test_dataset):\n",
    "    if args.gpu:\n",
    "        adj = Variable(data[\"adj\"].float(), requires_grad=False).cuda()\n",
    "        h0 = Variable(data[\"feats\"].float()).cuda()\n",
    "        targets = data[\"label\"].long().numpy()\n",
    "        labels.append(data[\"label\"].long().numpy())\n",
    "        batch_num_nodes = data[\"num_nodes\"].int().numpy()\n",
    "        assign_input = Variable(\n",
    "            data[\"assign_feats\"].float(), requires_grad=False\n",
    "        ).cuda()\n",
    "    else:\n",
    "        adj = Variable(data[\"adj\"].float(), requires_grad=False)\n",
    "        h0 = Variable(data[\"feats\"].float())\n",
    "        targets = data[\"label\"].long().numpy()\n",
    "        labels.append(data[\"label\"].long().numpy())\n",
    "        batch_num_nodes = data[\"num_nodes\"].int().numpy()\n",
    "        assign_input = Variable(\n",
    "            data[\"assign_feats\"].float(), requires_grad=False\n",
    "        )\n",
    "\n",
    "    edge_index = []\n",
    "    for a in adj:\n",
    "        edge_index.append(from_adj_to_edge_index(a))\n",
    "        \n",
    "    for i in range(len(edge_index)):   \n",
    "        edge_mask = explain_gnnexplainer(model, -1, h0[i], edge_index[i], targets[i], device, args)\n",
    "        edge_masks.append(edge_mask)\n",
    "    \n",
    "    ypred = model(h0, edge_index, batch_num_nodes, assign_x=assign_input)\n",
    "    _, indices = torch.max(ypred, 1)\n",
    "    preds.append(indices.cpu().data.numpy())\n",
    "\n",
    "\"\"\"    if max_num_examples is not None:\n",
    "        if (batch_idx + 1) * args.batch_size > max_num_examples:\n",
    "            break\"\"\"\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Softmax\n",
    "##### Fidelity #####\n",
    "\n",
    "def eval_gnn(model, dataset, edge_index=None, max_num_examples=None):\n",
    "    model.eval()\n",
    "    labels = []\n",
    "    preds = []\n",
    "    for batch_idx, data in enumerate(dataset):\n",
    "        if args.gpu:\n",
    "            adj = Variable(data[\"adj\"].float(), requires_grad=False).cuda()\n",
    "            h0 = Variable(data[\"feats\"].float()).cuda()\n",
    "            labels.append(data[\"label\"].long().numpy())\n",
    "            batch_num_nodes = data[\"num_nodes\"].int().numpy()\n",
    "            assign_input = Variable(\n",
    "                data[\"assign_feats\"].float(), requires_grad=False\n",
    "            ).cuda()\n",
    "        else:\n",
    "            adj = Variable(data[\"adj\"].float(), requires_grad=False)\n",
    "            h0 = Variable(data[\"feats\"].float())\n",
    "            labels.append(data[\"label\"].long().numpy())\n",
    "            batch_num_nodes = data[\"num_nodes\"].int().numpy()\n",
    "            assign_input = Variable(\n",
    "                data[\"assign_feats\"].float(), requires_grad=False\n",
    "            )\n",
    "        \n",
    "        if edge_index is None:\n",
    "            edge_index = []\n",
    "            for a in adj:\n",
    "                edge_index.append(from_adj_to_edge_index(a))\n",
    "                \n",
    "        ypred = model(h0, edge_index, batch_num_nodes, assign_x=assign_input)\n",
    "        _, indices = torch.max(ypred, 1)\n",
    "        preds.append(indices.cpu().data.numpy())\n",
    "\n",
    "        if max_num_examples is not None:\n",
    "            if (batch_idx + 1) * args.batch_size > max_num_examples:\n",
    "                break\n",
    "\n",
    "    labels = np.hstack(labels)\n",
    "    preds = np.hstack(preds)\n",
    "    return(ypred)\n",
    "    \n",
    "    \n",
    "def get_proba(ypred):\n",
    "    m = Softmax(dim=1)\n",
    "    yprob = m(ypred)\n",
    "    return yprob\n",
    "\n",
    "def get_labels(ypred):\n",
    "    ylabels = torch.argmax(ypred, dim=1)\n",
    "    return ylabels\n",
    "\n",
    "def list_to_dict(preds):\n",
    "    preds_dict=pd.DataFrame(preds).to_dict('list')\n",
    "    for key in preds_dict.keys():\n",
    "        preds_dict[key] = preds_dict[key][0]\n",
    "    return(preds_dict)\n",
    "\n",
    "def eval_related_pred_batch(model, dataset, edge_masks, device):\n",
    "    n_graphs = len(edge_masks)\n",
    "    \n",
    "    related_preds = []\n",
    "    ori_ypred = eval_gnn(model, dataset)\n",
    "    ori_yprob = get_proba(ori_ypred)\n",
    "\n",
    "    edge_index = []\n",
    "    for batch_idx, data in enumerate(dataset):\n",
    "        adj = Variable(data[\"adj\"].float(), requires_grad=False)\n",
    "        for a in adj:\n",
    "            edge_index.append(from_adj_to_edge_index(a))\n",
    "\n",
    "    mask_sparsity = 0\n",
    "    expl_edges = 0\n",
    "    for edge_mask in edge_masks:\n",
    "        mask_sparsity += 1.0 - (edge_mask != 0).sum() / len(edge_mask)\n",
    "        expl_edges += (edge_mask != 0).sum()\n",
    "    mask_sparsity /= len(edge_masks)\n",
    "    expl_edges /= len(edge_masks)\n",
    "\n",
    "    masked_edge_index = []\n",
    "    maskout_edge_index = []\n",
    "    \n",
    "    for i in range(n_graphs):\n",
    "        edge_mask = torch.Tensor(edge_masks[i])\n",
    "        indices = (np.where(edge_mask > 0)[0]).astype('int')\n",
    "        indices_inv = [i for i in range(len(edge_mask)) if i not in indices]\n",
    "\n",
    "        masked_edge_index.append(edge_index[i][:, indices].to(device))\n",
    "        maskout_edge_index.append(edge_index[i][:, indices_inv].to(device))\n",
    "\n",
    "    masked_ypred = eval_gnn(model, dataset, masked_edge_index)\n",
    "    masked_yprob = get_proba(masked_ypred)\n",
    "\n",
    "    maskout_ypred = eval_gnn(model, dataset, maskout_edge_index)\n",
    "    maskout_yprob = get_proba(maskout_ypred)\n",
    "\n",
    "    true_label = [data[\"label\"].long().numpy() for batch_idx, data in enumerate(dataset)]\n",
    "    pred_label = get_labels(ori_ypred)\n",
    "    print(true_label)\n",
    "    print(pred_label)\n",
    "    # assert true_label == pred_label, \"The label predicted by the GCN does not match the true label.\"\n",
    "\n",
    "    related_preds.append({'n_graphs': n_graphs,\n",
    "                          'masked': masked_yprob,\n",
    "                          'maskout': maskout_yprob,\n",
    "                          'origin': ori_yprob,\n",
    "                          'mask_sparsity': mask_sparsity,\n",
    "                          'expl_edges': expl_edges,\n",
    "                          'true_label': true_label,\n",
    "                          'pred_label': pred_label})\n",
    "\n",
    "    related_preds = list_to_dict(related_preds)\n",
    "    return related_preds\n",
    "\n",
    "\n",
    "def fidelity_acc(related_preds):\n",
    "    labels = related_preds['true_label']\n",
    "    ori_labels = np.argmax(related_preds['origin'], axis=1)\n",
    "    unimportant_labels = np.argmax(related_preds['maskout'], axis=1)\n",
    "    p_1 = np.array(ori_labels == labels).astype(int)\n",
    "    p_2 = np.array(unimportant_labels == labels).astype(int)\n",
    "    drop_probability = p_1 - p_2\n",
    "    return drop_probability.mean().item()\n",
    "\n",
    "\n",
    "def fidelity_acc_inv(related_preds):\n",
    "    labels = related_preds['true_label']\n",
    "    ori_labels = np.argmax(related_preds['origin'], axis=1)\n",
    "    important_labels = np.argmax(related_preds['masked'], axis=1)\n",
    "    p_1 = np.array([ori_labels == labels]).astype(int)\n",
    "    p_2 = np.array([important_labels == labels]).astype(int)\n",
    "    drop_probability = p_1 - p_2\n",
    "    return drop_probability.mean().item()\n",
    "\n",
    "\n",
    "# Fidelity+  metric  studies  the  prediction  change  by\n",
    "# removing  important  nodes/edges/node  features.\n",
    "# Higher fidelity+ value indicates good explanations -->1\n",
    "def fidelity_prob(related_preds):\n",
    "    labels = related_preds['true_label']\n",
    "    ori_probs = np.choose(labels, related_preds['origin'].T)\n",
    "    unimportant_probs = np.choose(labels, related_preds['maskout'].T)\n",
    "    drop_probability = ori_probs - unimportant_probs\n",
    "    return drop_probability.mean().item()\n",
    "\n",
    "\n",
    "# Fidelity-  metric  studies  the  prediction  change  by\n",
    "# removing  unimportant  nodes/edges/node  features.\n",
    "# Lower fidelity- value indicates good explanations -->0\n",
    "def fidelity_prob_inv(related_preds):\n",
    "    labels = related_preds['true_label']\n",
    "    ori_probs = np.choose(labels, related_preds['origin'].T)\n",
    "    important_probs = np.choose(labels, related_preds['masked'].T)\n",
    "    drop_probability = ori_probs - important_probs\n",
    "    return drop_probability.mean().item()\n",
    "\n",
    "\n",
    "def eval_fidelity(related_preds):\n",
    "    fidelity_scores = {\n",
    "        \"fidelity_acc+\": fidelity_acc(related_preds),\n",
    "        \"fidelity_acc-\": fidelity_acc_inv(related_preds),\n",
    "        \"fidelity_prob+\": fidelity_prob(related_preds),\n",
    "        \"fidelity_prob-\": fidelity_prob_inv(related_preds),\n",
    "    }\n",
    "    return fidelity_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([20, 28, 28])\n",
      "1\n",
      "torch.Size([20, 28, 28])\n",
      "2\n",
      "torch.Size([20, 28, 28])\n",
      "3\n",
      "torch.Size([20, 28, 28])\n",
      "4\n",
      "torch.Size([20, 28, 28])\n",
      "5\n",
      "torch.Size([20, 28, 28])\n",
      "6\n",
      "torch.Size([20, 28, 28])\n",
      "7\n",
      "torch.Size([10, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, data in enumerate(train_dataset):\n",
    "        adj = Variable(data[\"adj\"].float(), requires_grad=False)\n",
    "        print(batch_idx)\n",
    "        print(adj.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = eval_gnn(model, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.9451e-01, 4.0550e-01],\n",
       "        [9.8228e-01, 1.7723e-02],\n",
       "        [1.9598e-03, 9.9804e-01],\n",
       "        [9.5096e-01, 4.9043e-02],\n",
       "        [4.6956e-04, 9.9953e-01],\n",
       "        [6.7413e-03, 9.9326e-01],\n",
       "        [1.4489e-02, 9.8551e-01],\n",
       "        [1.2257e-02, 9.8774e-01],\n",
       "        [9.8511e-04, 9.9901e-01],\n",
       "        [8.5292e-01, 1.4708e-01],\n",
       "        [2.6473e-04, 9.9974e-01],\n",
       "        [9.0231e-03, 9.9098e-01],\n",
       "        [1.1033e-01, 8.8967e-01],\n",
       "        [9.3267e-01, 6.7331e-02],\n",
       "        [9.1754e-02, 9.0825e-01],\n",
       "        [2.5064e-04, 9.9975e-01],\n",
       "        [3.4923e-04, 9.9965e-01],\n",
       "        [8.6753e-01, 1.3247e-01],\n",
       "        [9.4575e-01, 5.4246e-02]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = get_proba(preds)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = get_labels(preds)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 38 is out of bounds for dimension 0 with size 38",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-afb6e517292b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_related_pred_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-74-4014d3a7cc77>\u001b[0m in \u001b[0;36meval_related_pred_batch\u001b[0;34m(model, dataset, edge_masks, device)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mindices_inv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mmasked_edge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mmaskout_edge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices_inv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 38 is out of bounds for dimension 0 with size 38"
     ]
    }
   ],
   "source": [
    "eval_related_pred_batch(model, train_dataset, edge_masks, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
